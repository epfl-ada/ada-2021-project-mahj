{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "32e2cf4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import bz2\n",
    "import json\n",
    "import re\n",
    "import Constants\n",
    "\n",
    "from urllib.parse import urlparse\n",
    "from tld import get_tld\n",
    "from Helper import extract_domain\n",
    "\n",
    "pd.set_option('display.max_colwidth', None) #Print full text\n",
    "pd.set_option('display.max_rows', 200) #Print full text\n",
    "\n",
    "CHUNK_SIZE = 10_000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8bc423b",
   "metadata": {},
   "source": [
    "### Compute basic files  statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f2a28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_reader = pd.read_json(FILE_QUOTES,lines=True,chunksize=CHUNK_SIZE,compression='bz2') \n",
    "\n",
    "quotes_count = 0\n",
    "unique_quotes_count = 0\n",
    "not_NONE_quotes_count = 0\n",
    "for (counter, df_chunk) in enumerate(json_reader):\n",
    "    \n",
    "    unique_quotes_count+= len(df_chunk)\n",
    "    df_chunk['quote_counts']= df_chunk['urls'].apply(lambda urls: len(urls))\n",
    "    quotes_count += df_chunk['quote_counts'].sum()\n",
    "    not_NONE_quotes_count += df_chunk[df_chunk['speaker']!='None']['quote_counts'].sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "9046311a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique quotes 5244449\n",
      "Quotes appearance count 17057653\n",
      "Quotes appearance count where speaker is not None 11200295\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of unique quotes {unique_quotes_count}')\n",
    "\n",
    "#We are not using num_occurences but rather the number of urls to quantify the number of quotes because\n",
    "# around 3% of quotes appear multiple times in the same article which increases numOccurences but is not \n",
    "#relevant in this study\n",
    "print(f'Quotes appearance count {quotes_count}')\n",
    "print(f'Quotes appearance count where speaker is not None {not_NONE_quotes_count}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4048577b",
   "metadata": {},
   "source": [
    "### Create speaker-newspaper dataframe\n",
    "df['newspaper','speaker','proba'] with possible duplicates if speaker was cited multiple times by the newspaper.\n",
    "Quotes with the most probable speaker cited as None are kept and removed furhter down the pipeline if necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "3abd2926",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process chunk 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/c6/nkvhnnln1739v3k9ryxjwq700000gn/T/ipykernel_84059/2165798071.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_chunk[\"proba\"] = df_chunk[\"probas\"].apply(lambda probas: float(probas[0][1]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process chunk 2\n",
      "Process chunk 3\n",
      "Process chunk 4\n",
      "Process chunk 5\n",
      "Process chunk 6\n",
      "Process chunk 7\n",
      "Process chunk 8\n",
      "Process chunk 9\n",
      "Process chunk 10\n",
      "Process chunk 11\n",
      "Process chunk 12\n",
      "Process chunk 13\n",
      "Process chunk 14\n",
      "Process chunk 15\n",
      "Process chunk 16\n",
      "Process chunk 17\n",
      "Process chunk 18\n",
      "Process chunk 19\n",
      "Process chunk 20\n",
      "Process chunk 21\n",
      "Process chunk 22\n",
      "Process chunk 23\n",
      "Process chunk 24\n",
      "Process chunk 25\n",
      "Process chunk 26\n",
      "Process chunk 27\n",
      "Process chunk 28\n",
      "Process chunk 29\n",
      "Process chunk 30\n",
      "Process chunk 31\n",
      "Process chunk 32\n",
      "Process chunk 33\n",
      "Process chunk 34\n",
      "Process chunk 35\n",
      "Process chunk 36\n",
      "Process chunk 37\n",
      "Process chunk 38\n",
      "Process chunk 39\n",
      "Process chunk 40\n",
      "Process chunk 41\n",
      "Process chunk 42\n",
      "Process chunk 43\n",
      "Process chunk 44\n",
      "Process chunk 45\n",
      "Process chunk 46\n",
      "Process chunk 47\n",
      "Process chunk 48\n",
      "Process chunk 49\n",
      "Process chunk 50\n",
      "Process chunk 51\n",
      "Process chunk 52\n",
      "Process chunk 53\n",
      "Process chunk 54\n",
      "Process chunk 55\n",
      "Process chunk 56\n",
      "Process chunk 57\n",
      "Process chunk 58\n",
      "Process chunk 59\n",
      "Process chunk 60\n",
      "Process chunk 61\n",
      "Process chunk 62\n",
      "Process chunk 63\n",
      "Process chunk 64\n",
      "Process chunk 65\n",
      "Process chunk 66\n",
      "Process chunk 67\n",
      "Process chunk 68\n",
      "Process chunk 69\n",
      "Process chunk 70\n",
      "Process chunk 71\n",
      "Process chunk 72\n",
      "Process chunk 73\n",
      "Process chunk 74\n",
      "Process chunk 75\n",
      "Process chunk 76\n",
      "Process chunk 77\n",
      "Process chunk 78\n",
      "Process chunk 79\n",
      "Process chunk 80\n",
      "Process chunk 81\n",
      "Process chunk 82\n",
      "Process chunk 83\n",
      "Process chunk 84\n",
      "Process chunk 85\n",
      "Process chunk 86\n",
      "Process chunk 87\n",
      "Process chunk 88\n",
      "Process chunk 89\n",
      "Process chunk 90\n",
      "Process chunk 91\n",
      "Process chunk 92\n",
      "Process chunk 93\n",
      "Process chunk 94\n",
      "Process chunk 95\n",
      "Process chunk 96\n",
      "Process chunk 97\n",
      "Process chunk 98\n",
      "Process chunk 99\n",
      "Process chunk 100\n",
      "Process chunk 101\n",
      "Process chunk 102\n",
      "Process chunk 103\n",
      "Process chunk 104\n",
      "Process chunk 105\n",
      "Process chunk 106\n",
      "Process chunk 107\n",
      "Process chunk 108\n",
      "Process chunk 109\n",
      "Process chunk 110\n",
      "Process chunk 111\n",
      "Process chunk 112\n",
      "Process chunk 113\n",
      "Process chunk 114\n",
      "Process chunk 115\n",
      "Process chunk 116\n",
      "Process chunk 117\n",
      "Process chunk 118\n",
      "Process chunk 119\n",
      "Process chunk 120\n",
      "Process chunk 121\n",
      "Process chunk 122\n",
      "Process chunk 123\n",
      "Process chunk 124\n",
      "Process chunk 125\n",
      "Process chunk 126\n",
      "Process chunk 127\n",
      "Process chunk 128\n",
      "Process chunk 129\n",
      "Process chunk 130\n",
      "Process chunk 131\n",
      "Process chunk 132\n",
      "Process chunk 133\n",
      "Process chunk 134\n",
      "Process chunk 135\n",
      "Process chunk 136\n",
      "Process chunk 137\n",
      "Process chunk 138\n",
      "Process chunk 139\n",
      "Process chunk 140\n",
      "Process chunk 141\n",
      "Process chunk 142\n",
      "Process chunk 143\n",
      "Process chunk 144\n",
      "Process chunk 145\n",
      "Process chunk 146\n",
      "Process chunk 147\n",
      "Process chunk 148\n",
      "Process chunk 149\n",
      "Process chunk 150\n",
      "Process chunk 151\n",
      "Process chunk 152\n",
      "Process chunk 153\n",
      "Process chunk 154\n",
      "Process chunk 155\n",
      "Process chunk 156\n",
      "Process chunk 157\n",
      "Process chunk 158\n",
      "Process chunk 159\n",
      "Process chunk 160\n",
      "Process chunk 161\n",
      "Process chunk 162\n",
      "Process chunk 163\n",
      "Process chunk 164\n",
      "Process chunk 165\n",
      "Process chunk 166\n",
      "Process chunk 167\n",
      "Process chunk 168\n",
      "Process chunk 169\n",
      "Process chunk 170\n",
      "Process chunk 171\n",
      "Process chunk 172\n",
      "Process chunk 173\n",
      "Process chunk 174\n",
      "Process chunk 175\n",
      "Process chunk 176\n",
      "Process chunk 177\n",
      "Process chunk 178\n",
      "Process chunk 179\n",
      "Process chunk 180\n",
      "Process chunk 181\n",
      "Process chunk 182\n",
      "Process chunk 183\n",
      "Process chunk 184\n",
      "Process chunk 185\n",
      "Process chunk 186\n",
      "Process chunk 187\n",
      "Process chunk 188\n",
      "Process chunk 189\n",
      "Process chunk 190\n",
      "Process chunk 191\n",
      "Process chunk 192\n",
      "Process chunk 193\n",
      "Process chunk 194\n",
      "Process chunk 195\n",
      "Process chunk 196\n",
      "Process chunk 197\n",
      "Process chunk 198\n",
      "Process chunk 199\n",
      "Process chunk 200\n",
      "Process chunk 201\n",
      "Process chunk 202\n",
      "Process chunk 203\n",
      "Process chunk 204\n",
      "Process chunk 205\n",
      "Process chunk 206\n",
      "Process chunk 207\n",
      "Process chunk 208\n",
      "Process chunk 209\n",
      "Process chunk 210\n",
      "Process chunk 211\n",
      "Process chunk 212\n",
      "Process chunk 213\n",
      "Process chunk 214\n",
      "Process chunk 215\n",
      "Process chunk 216\n",
      "Process chunk 217\n",
      "Process chunk 218\n",
      "Process chunk 219\n",
      "Process chunk 220\n",
      "Process chunk 221\n",
      "Process chunk 222\n",
      "Process chunk 223\n",
      "Process chunk 224\n",
      "Process chunk 225\n",
      "Process chunk 226\n",
      "Process chunk 227\n",
      "Process chunk 228\n",
      "Process chunk 229\n",
      "Process chunk 230\n",
      "Process chunk 231\n",
      "Process chunk 232\n",
      "Process chunk 233\n",
      "Process chunk 234\n",
      "Process chunk 235\n",
      "Process chunk 236\n",
      "Process chunk 237\n",
      "Process chunk 238\n",
      "Process chunk 239\n",
      "Process chunk 240\n",
      "Process chunk 241\n",
      "Process chunk 242\n",
      "Process chunk 243\n",
      "Process chunk 244\n",
      "Process chunk 245\n",
      "Process chunk 246\n",
      "Process chunk 247\n",
      "Process chunk 248\n",
      "Process chunk 249\n",
      "Process chunk 250\n",
      "Process chunk 251\n",
      "Process chunk 252\n",
      "Process chunk 253\n",
      "Process chunk 254\n",
      "Process chunk 255\n",
      "Process chunk 256\n",
      "Process chunk 257\n",
      "Process chunk 258\n",
      "Process chunk 259\n",
      "Process chunk 260\n",
      "Process chunk 261\n",
      "Process chunk 262\n",
      "Process chunk 263\n",
      "Process chunk 264\n",
      "Process chunk 265\n",
      "Process chunk 266\n",
      "Process chunk 267\n",
      "Process chunk 268\n",
      "Process chunk 269\n",
      "Process chunk 270\n",
      "Process chunk 271\n",
      "Process chunk 272\n",
      "Process chunk 273\n",
      "Process chunk 274\n",
      "Process chunk 275\n",
      "Process chunk 276\n",
      "Process chunk 277\n",
      "Process chunk 278\n",
      "Process chunk 279\n",
      "Process chunk 280\n",
      "Process chunk 281\n",
      "Process chunk 282\n",
      "Process chunk 283\n",
      "Process chunk 284\n",
      "Process chunk 285\n",
      "Process chunk 286\n",
      "Process chunk 287\n",
      "Process chunk 288\n",
      "Process chunk 289\n",
      "Process chunk 290\n",
      "Process chunk 291\n",
      "Process chunk 292\n",
      "Process chunk 293\n",
      "Process chunk 294\n",
      "Process chunk 295\n",
      "Process chunk 296\n",
      "Process chunk 297\n",
      "Process chunk 298\n",
      "Process chunk 299\n",
      "Process chunk 300\n",
      "Process chunk 301\n",
      "Process chunk 302\n",
      "Process chunk 303\n",
      "Process chunk 304\n",
      "Process chunk 305\n",
      "Process chunk 306\n",
      "Process chunk 307\n",
      "Process chunk 308\n",
      "Process chunk 309\n",
      "Process chunk 310\n",
      "Process chunk 311\n",
      "Process chunk 312\n",
      "Process chunk 313\n",
      "Process chunk 314\n",
      "Process chunk 315\n",
      "Process chunk 316\n",
      "Process chunk 317\n",
      "Process chunk 318\n",
      "Process chunk 319\n",
      "Process chunk 320\n",
      "Process chunk 321\n",
      "Process chunk 322\n",
      "Process chunk 323\n",
      "Process chunk 324\n",
      "Process chunk 325\n",
      "Process chunk 326\n",
      "Process chunk 327\n",
      "Process chunk 328\n",
      "Process chunk 329\n",
      "Process chunk 330\n",
      "Process chunk 331\n",
      "Process chunk 332\n",
      "Process chunk 333\n",
      "Process chunk 334\n",
      "Process chunk 335\n",
      "Process chunk 336\n",
      "Process chunk 337\n",
      "Process chunk 338\n",
      "Process chunk 339\n",
      "Process chunk 340\n",
      "Process chunk 341\n",
      "Process chunk 342\n",
      "Process chunk 343\n",
      "Process chunk 344\n",
      "Process chunk 345\n",
      "Process chunk 346\n",
      "Process chunk 347\n",
      "Process chunk 348\n",
      "Process chunk 349\n",
      "Process chunk 350\n",
      "Process chunk 351\n",
      "Process chunk 352\n",
      "Process chunk 353\n",
      "Process chunk 354\n",
      "Process chunk 355\n",
      "Process chunk 356\n",
      "Process chunk 357\n",
      "Process chunk 358\n",
      "Process chunk 359\n",
      "Process chunk 360\n",
      "Process chunk 361\n",
      "Process chunk 362\n",
      "Process chunk 363\n",
      "Process chunk 364\n",
      "Process chunk 365\n",
      "Process chunk 366\n",
      "Process chunk 367\n",
      "Process chunk 368\n",
      "Process chunk 369\n",
      "Process chunk 370\n",
      "Process chunk 371\n",
      "Process chunk 372\n",
      "Process chunk 373\n",
      "Process chunk 374\n",
      "Process chunk 375\n",
      "Process chunk 376\n",
      "Process chunk 377\n",
      "Process chunk 378\n",
      "Process chunk 379\n",
      "Process chunk 380\n",
      "Process chunk 381\n",
      "Process chunk 382\n",
      "Process chunk 383\n",
      "Process chunk 384\n",
      "Process chunk 385\n",
      "Process chunk 386\n",
      "Process chunk 387\n",
      "Process chunk 388\n",
      "Process chunk 389\n",
      "Process chunk 390\n",
      "Process chunk 391\n",
      "Process chunk 392\n",
      "Process chunk 393\n",
      "Process chunk 394\n",
      "Process chunk 395\n",
      "Process chunk 396\n",
      "Process chunk 397\n",
      "Process chunk 398\n",
      "Process chunk 399\n",
      "Process chunk 400\n",
      "Process chunk 401\n",
      "Process chunk 402\n",
      "Process chunk 403\n",
      "Process chunk 404\n",
      "Process chunk 405\n",
      "Process chunk 406\n",
      "Process chunk 407\n",
      "Process chunk 408\n",
      "Process chunk 409\n",
      "Process chunk 410\n",
      "Process chunk 411\n",
      "Process chunk 412\n",
      "Process chunk 413\n",
      "Process chunk 414\n",
      "Process chunk 415\n",
      "Process chunk 416\n",
      "Process chunk 417\n",
      "Process chunk 418\n",
      "Process chunk 419\n",
      "Process chunk 420\n",
      "Process chunk 421\n",
      "Process chunk 422\n",
      "Process chunk 423\n",
      "Process chunk 424\n",
      "Process chunk 425\n",
      "Process chunk 426\n",
      "Process chunk 427\n",
      "Process chunk 428\n",
      "Process chunk 429\n",
      "Process chunk 430\n",
      "Process chunk 431\n",
      "Process chunk 432\n",
      "Process chunk 433\n",
      "Process chunk 434\n",
      "Process chunk 435\n",
      "Process chunk 436\n",
      "Process chunk 437\n",
      "Process chunk 438\n",
      "Process chunk 439\n",
      "Process chunk 440\n",
      "Process chunk 441\n",
      "Process chunk 442\n",
      "Process chunk 443\n",
      "Process chunk 444\n",
      "Process chunk 445\n",
      "Process chunk 446\n",
      "Process chunk 447\n",
      "Process chunk 448\n",
      "Process chunk 449\n",
      "Process chunk 450\n",
      "Process chunk 451\n",
      "Process chunk 452\n",
      "Process chunk 453\n",
      "Process chunk 454\n",
      "Process chunk 455\n",
      "Process chunk 456\n",
      "Process chunk 457\n",
      "Process chunk 458\n",
      "Process chunk 459\n",
      "Process chunk 460\n",
      "Process chunk 461\n",
      "Process chunk 462\n",
      "Process chunk 463\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process chunk 464\n",
      "Process chunk 465\n",
      "Process chunk 466\n",
      "Process chunk 467\n",
      "Process chunk 468\n",
      "Process chunk 469\n",
      "Process chunk 470\n",
      "Process chunk 471\n",
      "Process chunk 472\n",
      "Process chunk 473\n",
      "Process chunk 474\n",
      "Process chunk 475\n",
      "Process chunk 476\n",
      "Process chunk 477\n",
      "Process chunk 478\n",
      "Process chunk 479\n",
      "Process chunk 480\n",
      "Process chunk 481\n",
      "Process chunk 482\n",
      "Process chunk 483\n",
      "Process chunk 484\n",
      "Process chunk 485\n",
      "Process chunk 486\n",
      "Process chunk 487\n",
      "Process chunk 488\n",
      "Process chunk 489\n",
      "Process chunk 490\n",
      "Process chunk 491\n",
      "Process chunk 492\n",
      "Process chunk 493\n",
      "Process chunk 494\n",
      "Process chunk 495\n",
      "Process chunk 496\n",
      "Process chunk 497\n",
      "Process chunk 498\n",
      "Process chunk 499\n",
      "Process chunk 500\n",
      "Process chunk 501\n",
      "Process chunk 502\n",
      "Process chunk 503\n",
      "Process chunk 504\n",
      "Process chunk 505\n",
      "Process chunk 506\n",
      "Process chunk 507\n",
      "Process chunk 508\n",
      "Process chunk 509\n",
      "Process chunk 510\n",
      "Process chunk 511\n",
      "Process chunk 512\n",
      "Process chunk 513\n",
      "Process chunk 514\n",
      "Process chunk 515\n",
      "Process chunk 516\n",
      "Process chunk 517\n",
      "Process chunk 518\n",
      "Process chunk 519\n",
      "Process chunk 520\n",
      "Process chunk 521\n",
      "Process chunk 522\n",
      "Process chunk 523\n",
      "Process chunk 524\n",
      "Process chunk 525\n"
     ]
    }
   ],
   "source": [
    "json_reader = pd.read_json(FILE_QUOTES,lines=True,chunksize=CHUNK_SIZE,compression='bz2') \n",
    "\n",
    "for (counter, df_chunk) in enumerate(json_reader):\n",
    "\n",
    "    print(f\"Process chunk {counter+1}\")\n",
    "    \n",
    "    df_chunk = df_chunk[[\"probas\",\"urls\",\"speaker\"]]\n",
    "    \n",
    "    df_chunk[\"proba\"] = df_chunk[\"probas\"].apply(lambda probas: float(probas[0][1]))\n",
    "    \n",
    "    df_chunk = df_chunk.explode(\"urls\")\n",
    "    df_chunk[\"newspaper\"] = df_chunk[\"urls\"].apply(extract_domain)\n",
    "    \n",
    "    #We keep None values and remove it further down the pipeline if needed\n",
    "    df_speakers = df_chunk[[\"newspaper\", \"speaker\",\"proba\"]]\n",
    "    \n",
    "    add_header = (counter==0)\n",
    "    write_mode = 'w' if counter == 0 else 'a'\n",
    "    df_speakers.to_csv(NEWSPAPER_SPEAKERS_FILE,header = add_header,index=False, mode=write_mode,compression='bz2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c6f8dc",
   "metadata": {},
   "source": [
    "### For each speaker preprocess its name and compute the number of times it appeared in the articles\n",
    "For now, the certainty probability of a quote's speaker being correct is not taken into account and every (newspaper,speaker) pair is kept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2b7a3510",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_speaker(speaker):\n",
    "    #Lower case the names and remove all non alpha numeric characters\n",
    "    new_name = speaker.lower()\n",
    "    new_name = re.sub(r'[^A-Za-z0-9 ]+', '', new_name)\n",
    "    return new_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3be26f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The file is small enough to be loaded in memory\n",
    "df = pd.read_csv(FILE_NEWSPAPER_SPEAKER,compression='bz2')\n",
    "previous_speaker_count = len(df['speaker'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a97319ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['speaker'] = df['speaker'].apply(process_speaker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "cb06a6eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The previous unique speaker count was 218415 and the new unique speaker count is 212147\n",
      "This correspond to a 2.87% reduction\n"
     ]
    }
   ],
   "source": [
    "processed_speaker_count = len(df['speaker'].unique())\n",
    "\n",
    "print(f'The previous unique speaker count was {previous_speaker_count} and the new unique speaker count is {processed_speaker_count}')\n",
    "print(f'This correspond to a {(previous_speaker_count-processed_speaker_count)/previous_speaker_count:.2%} reduction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "942a4e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "newspaper_speaker_count = df.groupby(['newspaper','speaker'],as_index=False).count()\\\n",
    "                            .rename(columns = {'proba':'count'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d0a29855",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>newspaper</th>\n",
       "      <th>speaker</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1011now</td>\n",
       "      <td>adam morfeld</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1011now</td>\n",
       "      <td>adam schiff</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1011now</td>\n",
       "      <td>adrian smith</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1011now</td>\n",
       "      <td>alexandra brown</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1011now</td>\n",
       "      <td>alfonso morales</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2434405</th>\n",
       "      <td>zigwheels</td>\n",
       "      <td>srinivas reddy</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2434406</th>\n",
       "      <td>zigwheels</td>\n",
       "      <td>toby price</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2434407</th>\n",
       "      <td>zigwheels</td>\n",
       "      <td>yash aradhya</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2434408</th>\n",
       "      <td>zip06</td>\n",
       "      <td>mike caruso</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2434409</th>\n",
       "      <td>zip06</td>\n",
       "      <td>none</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2434410 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         newspaper          speaker  count\n",
       "0          1011now     adam morfeld      4\n",
       "1          1011now      adam schiff      2\n",
       "2          1011now     adrian smith      2\n",
       "3          1011now  alexandra brown      1\n",
       "4          1011now  alfonso morales      1\n",
       "...            ...              ...    ...\n",
       "2434405  zigwheels   srinivas reddy      1\n",
       "2434406  zigwheels       toby price      1\n",
       "2434407  zigwheels     yash aradhya      1\n",
       "2434408      zip06      mike caruso     16\n",
       "2434409      zip06             none      2\n",
       "\n",
       "[2434410 rows x 3 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newspaper_speaker_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "aa9d3c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "newspaper_speaker_count.to_csv(FILE_NEWSPAPER_SPEAKER_COUNT,header = True,index=False, mode='w',compression='bz2')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
