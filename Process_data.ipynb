{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97e4e01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Constants import *\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None) #Print full text\n",
    "pd.set_option('display.max_rows', 200) #Print full text\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "en_stopwords = set(stopwords.words(\"english\"))\n",
    "en_stopwords.update([s.capitalize() for s in stopwords.words(\"english\")])\n",
    "\n",
    "import bz2\n",
    "import json\n",
    "import re\n",
    "import string\n",
    "import ast\n",
    "\n",
    "from urllib.parse import urlparse\n",
    "from tld import get_tld\n",
    "\n",
    "from collections import Counter\n",
    "from itertools import chain\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "\n",
    "from scipy import sparse\n",
    "from scipy.sparse import csr_matrix, dok_matrix\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5743c298",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_domain(url):\n",
    "    \"\"\"\n",
    "    Extract domain of an url\n",
    "    \"\"\"\n",
    "    url_pruned = urlparse(url).netloc\n",
    "    tld = get_tld(url, as_object=True).tld\n",
    "    url_no_tld = url_pruned.replace('.'+tld,\"\")\n",
    "    domain = url_no_tld.split('.')[-1]\n",
    "\n",
    "    return domain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8bc423b",
   "metadata": {},
   "source": [
    "## Compute basic statistics about the quotes file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10f2a28a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique quotes 5244449\n",
      "Quotes appearance count 17057653\n",
      "Quotes appearance count where speaker is not None 11200295\n"
     ]
    }
   ],
   "source": [
    "CHUNK_SIZE = 10_000\n",
    "\n",
    "json_reader = pd.read_json(FILE_QUOTES,lines=True,chunksize=CHUNK_SIZE,compression='bz2') \n",
    "\n",
    "quotes_count = 0\n",
    "unique_quotes_count = 0\n",
    "not_NONE_quotes_count = 0\n",
    "for (counter, df_chunk) in enumerate(json_reader):\n",
    "    \n",
    "    unique_quotes_count+= len(df_chunk)\n",
    "    df_chunk['quote_counts']= df_chunk['urls'].apply(lambda urls: len(urls))\n",
    "    quotes_count += df_chunk['quote_counts'].sum()\n",
    "    not_NONE_quotes_count += df_chunk[df_chunk['speaker']!='None']['quote_counts'].sum() \n",
    "    \n",
    "print(f'Number of unique quotes {unique_quotes_count}')\n",
    "\n",
    "#We are not using num_occurences but rather the number of urls to quantify the number of quotes because\n",
    "# around 3% of quotes appear multiple times in the same article which increases numOccurences but is not \n",
    "#relevant in this study\n",
    "print(f'Quotes appearance count {quotes_count}')\n",
    "print(f'Quotes appearance count where speaker is not None {not_NONE_quotes_count}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba9575c",
   "metadata": {},
   "source": [
    "## Speaker pipeline\n",
    "From the quote file we create a TFIDF matrix of newspaper x speaker.\n",
    "1) Create speaker-newspaper dataframe  \n",
    "2) For each speaker preprocess its name and compute the number of times it appeared in the articles  \n",
    "3) Create newspaper set and indexes  \n",
    "4) Create speaker set and indexes  \n",
    "5) Create frequency matrix  \n",
    "6) Create TF-IDF matrix and write it to a file  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4048577b",
   "metadata": {},
   "source": [
    "### 1) Create speaker-newspaper dataframe\n",
    "df['newspaper','speaker','proba'] with possible duplicates if speaker was cited multiple times by the newspaper.\n",
    "Quotes with the most probable speaker cited as None are kept and removed further down the pipeline if necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9d07969",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process chunk 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vq/xks_4c213rdb38bljjc08hpr0000gp/T/ipykernel_33367/12216240.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_chunk[\"proba\"] = df_chunk[\"probas\"].apply(lambda probas: float(probas[0][1]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process chunk 2\n",
      "Process chunk 3\n",
      "Process chunk 4\n",
      "Process chunk 5\n",
      "Process chunk 6\n",
      "Process chunk 7\n",
      "Process chunk 8\n",
      "Process chunk 9\n",
      "Process chunk 10\n",
      "Process chunk 11\n",
      "Process chunk 12\n",
      "Process chunk 13\n",
      "Process chunk 14\n",
      "Process chunk 15\n",
      "Process chunk 16\n",
      "Process chunk 17\n",
      "Process chunk 18\n",
      "Process chunk 19\n",
      "Process chunk 20\n",
      "Process chunk 21\n",
      "Process chunk 22\n",
      "Process chunk 23\n",
      "Process chunk 24\n",
      "Process chunk 25\n",
      "Process chunk 26\n",
      "Process chunk 27\n",
      "Process chunk 28\n",
      "Process chunk 29\n",
      "Process chunk 30\n",
      "Process chunk 31\n",
      "Process chunk 32\n",
      "Process chunk 33\n",
      "Process chunk 34\n",
      "Process chunk 35\n",
      "Process chunk 36\n",
      "Process chunk 37\n",
      "Process chunk 38\n",
      "Process chunk 39\n",
      "Process chunk 40\n",
      "Process chunk 41\n",
      "Process chunk 42\n",
      "Process chunk 43\n",
      "Process chunk 44\n",
      "Process chunk 45\n",
      "Process chunk 46\n",
      "Process chunk 47\n",
      "Process chunk 48\n",
      "Process chunk 49\n",
      "Process chunk 50\n",
      "Process chunk 51\n",
      "Process chunk 52\n",
      "Process chunk 53\n",
      "Process chunk 54\n",
      "Process chunk 55\n",
      "Process chunk 56\n",
      "Process chunk 57\n",
      "Process chunk 58\n",
      "Process chunk 59\n",
      "Process chunk 60\n",
      "Process chunk 61\n",
      "Process chunk 62\n",
      "Process chunk 63\n",
      "Process chunk 64\n",
      "Process chunk 65\n",
      "Process chunk 66\n",
      "Process chunk 67\n",
      "Process chunk 68\n",
      "Process chunk 69\n",
      "Process chunk 70\n",
      "Process chunk 71\n",
      "Process chunk 72\n",
      "Process chunk 73\n",
      "Process chunk 74\n",
      "Process chunk 75\n",
      "Process chunk 76\n",
      "Process chunk 77\n",
      "Process chunk 78\n",
      "Process chunk 79\n",
      "Process chunk 80\n",
      "Process chunk 81\n",
      "Process chunk 82\n",
      "Process chunk 83\n",
      "Process chunk 84\n",
      "Process chunk 85\n",
      "Process chunk 86\n",
      "Process chunk 87\n",
      "Process chunk 88\n",
      "Process chunk 89\n",
      "Process chunk 90\n",
      "Process chunk 91\n",
      "Process chunk 92\n",
      "Process chunk 93\n",
      "Process chunk 94\n",
      "Process chunk 95\n",
      "Process chunk 96\n",
      "Process chunk 97\n",
      "Process chunk 98\n",
      "Process chunk 99\n",
      "Process chunk 100\n",
      "Process chunk 101\n",
      "Process chunk 102\n",
      "Process chunk 103\n",
      "Process chunk 104\n",
      "Process chunk 105\n",
      "Process chunk 106\n",
      "Process chunk 107\n",
      "Process chunk 108\n",
      "Process chunk 109\n",
      "Process chunk 110\n",
      "Process chunk 111\n",
      "Process chunk 112\n",
      "Process chunk 113\n",
      "Process chunk 114\n",
      "Process chunk 115\n",
      "Process chunk 116\n",
      "Process chunk 117\n",
      "Process chunk 118\n",
      "Process chunk 119\n",
      "Process chunk 120\n",
      "Process chunk 121\n",
      "Process chunk 122\n",
      "Process chunk 123\n",
      "Process chunk 124\n",
      "Process chunk 125\n",
      "Process chunk 126\n",
      "Process chunk 127\n",
      "Process chunk 128\n",
      "Process chunk 129\n",
      "Process chunk 130\n",
      "Process chunk 131\n",
      "Process chunk 132\n",
      "Process chunk 133\n",
      "Process chunk 134\n",
      "Process chunk 135\n",
      "Process chunk 136\n",
      "Process chunk 137\n",
      "Process chunk 138\n",
      "Process chunk 139\n",
      "Process chunk 140\n",
      "Process chunk 141\n",
      "Process chunk 142\n",
      "Process chunk 143\n",
      "Process chunk 144\n",
      "Process chunk 145\n",
      "Process chunk 146\n",
      "Process chunk 147\n",
      "Process chunk 148\n",
      "Process chunk 149\n",
      "Process chunk 150\n",
      "Process chunk 151\n",
      "Process chunk 152\n",
      "Process chunk 153\n",
      "Process chunk 154\n",
      "Process chunk 155\n",
      "Process chunk 156\n",
      "Process chunk 157\n",
      "Process chunk 158\n",
      "Process chunk 159\n",
      "Process chunk 160\n",
      "Process chunk 161\n",
      "Process chunk 162\n",
      "Process chunk 163\n",
      "Process chunk 164\n",
      "Process chunk 165\n",
      "Process chunk 166\n",
      "Process chunk 167\n",
      "Process chunk 168\n",
      "Process chunk 169\n",
      "Process chunk 170\n",
      "Process chunk 171\n",
      "Process chunk 172\n",
      "Process chunk 173\n",
      "Process chunk 174\n",
      "Process chunk 175\n",
      "Process chunk 176\n",
      "Process chunk 177\n",
      "Process chunk 178\n",
      "Process chunk 179\n",
      "Process chunk 180\n",
      "Process chunk 181\n",
      "Process chunk 182\n",
      "Process chunk 183\n",
      "Process chunk 184\n",
      "Process chunk 185\n",
      "Process chunk 186\n",
      "Process chunk 187\n",
      "Process chunk 188\n",
      "Process chunk 189\n",
      "Process chunk 190\n",
      "Process chunk 191\n",
      "Process chunk 192\n",
      "Process chunk 193\n",
      "Process chunk 194\n",
      "Process chunk 195\n",
      "Process chunk 196\n",
      "Process chunk 197\n",
      "Process chunk 198\n",
      "Process chunk 199\n",
      "Process chunk 200\n",
      "Process chunk 201\n",
      "Process chunk 202\n",
      "Process chunk 203\n",
      "Process chunk 204\n",
      "Process chunk 205\n",
      "Process chunk 206\n",
      "Process chunk 207\n",
      "Process chunk 208\n",
      "Process chunk 209\n",
      "Process chunk 210\n",
      "Process chunk 211\n",
      "Process chunk 212\n",
      "Process chunk 213\n",
      "Process chunk 214\n",
      "Process chunk 215\n",
      "Process chunk 216\n",
      "Process chunk 217\n",
      "Process chunk 218\n",
      "Process chunk 219\n",
      "Process chunk 220\n",
      "Process chunk 221\n",
      "Process chunk 222\n",
      "Process chunk 223\n",
      "Process chunk 224\n",
      "Process chunk 225\n",
      "Process chunk 226\n",
      "Process chunk 227\n",
      "Process chunk 228\n",
      "Process chunk 229\n",
      "Process chunk 230\n",
      "Process chunk 231\n",
      "Process chunk 232\n",
      "Process chunk 233\n",
      "Process chunk 234\n",
      "Process chunk 235\n",
      "Process chunk 236\n",
      "Process chunk 237\n",
      "Process chunk 238\n",
      "Process chunk 239\n",
      "Process chunk 240\n",
      "Process chunk 241\n",
      "Process chunk 242\n",
      "Process chunk 243\n",
      "Process chunk 244\n",
      "Process chunk 245\n",
      "Process chunk 246\n",
      "Process chunk 247\n",
      "Process chunk 248\n",
      "Process chunk 249\n",
      "Process chunk 250\n",
      "Process chunk 251\n",
      "Process chunk 252\n",
      "Process chunk 253\n",
      "Process chunk 254\n",
      "Process chunk 255\n",
      "Process chunk 256\n",
      "Process chunk 257\n",
      "Process chunk 258\n",
      "Process chunk 259\n",
      "Process chunk 260\n",
      "Process chunk 261\n",
      "Process chunk 262\n",
      "Process chunk 263\n",
      "Process chunk 264\n",
      "Process chunk 265\n",
      "Process chunk 266\n",
      "Process chunk 267\n",
      "Process chunk 268\n",
      "Process chunk 269\n",
      "Process chunk 270\n",
      "Process chunk 271\n",
      "Process chunk 272\n",
      "Process chunk 273\n",
      "Process chunk 274\n",
      "Process chunk 275\n",
      "Process chunk 276\n",
      "Process chunk 277\n",
      "Process chunk 278\n",
      "Process chunk 279\n",
      "Process chunk 280\n",
      "Process chunk 281\n",
      "Process chunk 282\n",
      "Process chunk 283\n",
      "Process chunk 284\n",
      "Process chunk 285\n",
      "Process chunk 286\n",
      "Process chunk 287\n",
      "Process chunk 288\n",
      "Process chunk 289\n",
      "Process chunk 290\n",
      "Process chunk 291\n",
      "Process chunk 292\n",
      "Process chunk 293\n",
      "Process chunk 294\n",
      "Process chunk 295\n",
      "Process chunk 296\n",
      "Process chunk 297\n",
      "Process chunk 298\n",
      "Process chunk 299\n",
      "Process chunk 300\n",
      "Process chunk 301\n",
      "Process chunk 302\n",
      "Process chunk 303\n",
      "Process chunk 304\n",
      "Process chunk 305\n",
      "Process chunk 306\n",
      "Process chunk 307\n",
      "Process chunk 308\n",
      "Process chunk 309\n",
      "Process chunk 310\n",
      "Process chunk 311\n",
      "Process chunk 312\n",
      "Process chunk 313\n",
      "Process chunk 314\n",
      "Process chunk 315\n",
      "Process chunk 316\n",
      "Process chunk 317\n",
      "Process chunk 318\n",
      "Process chunk 319\n",
      "Process chunk 320\n",
      "Process chunk 321\n",
      "Process chunk 322\n",
      "Process chunk 323\n",
      "Process chunk 324\n",
      "Process chunk 325\n",
      "Process chunk 326\n",
      "Process chunk 327\n",
      "Process chunk 328\n",
      "Process chunk 329\n",
      "Process chunk 330\n",
      "Process chunk 331\n",
      "Process chunk 332\n",
      "Process chunk 333\n",
      "Process chunk 334\n",
      "Process chunk 335\n",
      "Process chunk 336\n",
      "Process chunk 337\n",
      "Process chunk 338\n",
      "Process chunk 339\n",
      "Process chunk 340\n",
      "Process chunk 341\n",
      "Process chunk 342\n",
      "Process chunk 343\n",
      "Process chunk 344\n",
      "Process chunk 345\n",
      "Process chunk 346\n",
      "Process chunk 347\n",
      "Process chunk 348\n",
      "Process chunk 349\n",
      "Process chunk 350\n",
      "Process chunk 351\n",
      "Process chunk 352\n",
      "Process chunk 353\n",
      "Process chunk 354\n",
      "Process chunk 355\n",
      "Process chunk 356\n",
      "Process chunk 357\n",
      "Process chunk 358\n",
      "Process chunk 359\n",
      "Process chunk 360\n",
      "Process chunk 361\n",
      "Process chunk 362\n",
      "Process chunk 363\n",
      "Process chunk 364\n",
      "Process chunk 365\n",
      "Process chunk 366\n",
      "Process chunk 367\n",
      "Process chunk 368\n",
      "Process chunk 369\n",
      "Process chunk 370\n",
      "Process chunk 371\n",
      "Process chunk 372\n",
      "Process chunk 373\n",
      "Process chunk 374\n",
      "Process chunk 375\n",
      "Process chunk 376\n",
      "Process chunk 377\n",
      "Process chunk 378\n",
      "Process chunk 379\n",
      "Process chunk 380\n",
      "Process chunk 381\n",
      "Process chunk 382\n",
      "Process chunk 383\n",
      "Process chunk 384\n",
      "Process chunk 385\n",
      "Process chunk 386\n",
      "Process chunk 387\n",
      "Process chunk 388\n",
      "Process chunk 389\n",
      "Process chunk 390\n",
      "Process chunk 391\n",
      "Process chunk 392\n",
      "Process chunk 393\n",
      "Process chunk 394\n",
      "Process chunk 395\n",
      "Process chunk 396\n",
      "Process chunk 397\n",
      "Process chunk 398\n",
      "Process chunk 399\n",
      "Process chunk 400\n",
      "Process chunk 401\n",
      "Process chunk 402\n",
      "Process chunk 403\n",
      "Process chunk 404\n",
      "Process chunk 405\n",
      "Process chunk 406\n",
      "Process chunk 407\n",
      "Process chunk 408\n",
      "Process chunk 409\n",
      "Process chunk 410\n",
      "Process chunk 411\n",
      "Process chunk 412\n",
      "Process chunk 413\n",
      "Process chunk 414\n",
      "Process chunk 415\n",
      "Process chunk 416\n",
      "Process chunk 417\n",
      "Process chunk 418\n",
      "Process chunk 419\n",
      "Process chunk 420\n",
      "Process chunk 421\n",
      "Process chunk 422\n",
      "Process chunk 423\n",
      "Process chunk 424\n",
      "Process chunk 425\n",
      "Process chunk 426\n",
      "Process chunk 427\n",
      "Process chunk 428\n",
      "Process chunk 429\n",
      "Process chunk 430\n",
      "Process chunk 431\n",
      "Process chunk 432\n",
      "Process chunk 433\n",
      "Process chunk 434\n",
      "Process chunk 435\n",
      "Process chunk 436\n",
      "Process chunk 437\n",
      "Process chunk 438\n",
      "Process chunk 439\n",
      "Process chunk 440\n",
      "Process chunk 441\n",
      "Process chunk 442\n",
      "Process chunk 443\n",
      "Process chunk 444\n",
      "Process chunk 445\n",
      "Process chunk 446\n",
      "Process chunk 447\n",
      "Process chunk 448\n",
      "Process chunk 449\n",
      "Process chunk 450\n",
      "Process chunk 451\n",
      "Process chunk 452\n",
      "Process chunk 453\n",
      "Process chunk 454\n",
      "Process chunk 455\n",
      "Process chunk 456\n",
      "Process chunk 457\n",
      "Process chunk 458\n",
      "Process chunk 459\n",
      "Process chunk 460\n",
      "Process chunk 461\n",
      "Process chunk 462\n",
      "Process chunk 463\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process chunk 464\n",
      "Process chunk 465\n",
      "Process chunk 466\n",
      "Process chunk 467\n",
      "Process chunk 468\n",
      "Process chunk 469\n",
      "Process chunk 470\n",
      "Process chunk 471\n",
      "Process chunk 472\n",
      "Process chunk 473\n",
      "Process chunk 474\n",
      "Process chunk 475\n",
      "Process chunk 476\n",
      "Process chunk 477\n",
      "Process chunk 478\n",
      "Process chunk 479\n",
      "Process chunk 480\n",
      "Process chunk 481\n",
      "Process chunk 482\n",
      "Process chunk 483\n",
      "Process chunk 484\n",
      "Process chunk 485\n",
      "Process chunk 486\n",
      "Process chunk 487\n",
      "Process chunk 488\n",
      "Process chunk 489\n",
      "Process chunk 490\n",
      "Process chunk 491\n",
      "Process chunk 492\n",
      "Process chunk 493\n",
      "Process chunk 494\n",
      "Process chunk 495\n",
      "Process chunk 496\n",
      "Process chunk 497\n",
      "Process chunk 498\n",
      "Process chunk 499\n",
      "Process chunk 500\n",
      "Process chunk 501\n",
      "Process chunk 502\n",
      "Process chunk 503\n",
      "Process chunk 504\n",
      "Process chunk 505\n",
      "Process chunk 506\n",
      "Process chunk 507\n",
      "Process chunk 508\n",
      "Process chunk 509\n",
      "Process chunk 510\n",
      "Process chunk 511\n",
      "Process chunk 512\n",
      "Process chunk 513\n",
      "Process chunk 514\n",
      "Process chunk 515\n",
      "Process chunk 516\n",
      "Process chunk 517\n",
      "Process chunk 518\n",
      "Process chunk 519\n",
      "Process chunk 520\n",
      "Process chunk 521\n",
      "Process chunk 522\n",
      "Process chunk 523\n",
      "Process chunk 524\n",
      "Process chunk 525\n"
     ]
    }
   ],
   "source": [
    "json_reader = pd.read_json(FILE_QUOTES,lines=True,chunksize=CHUNK_SIZE,compression='bz2') \n",
    "\n",
    "for (counter, df_chunk) in enumerate(json_reader):\n",
    "\n",
    "    print(f\"Process chunk {counter+1}\")\n",
    "    \n",
    "    df_chunk = df_chunk[[\"probas\",\"urls\",\"speaker\"]]\n",
    "    \n",
    "    df_chunk[\"proba\"] = df_chunk[\"probas\"].apply(lambda probas: float(probas[0][1]))\n",
    "    \n",
    "    df_chunk = df_chunk.explode(\"urls\")\n",
    "    df_chunk[\"newspaper\"] = df_chunk[\"urls\"].apply(extract_domain)\n",
    "    \n",
    "    #We keep None values and remove it further down the pipeline if needed\n",
    "    df_speakers = df_chunk[[\"newspaper\", \"speaker\",\"proba\"]]\n",
    "    \n",
    "    add_header = (counter==0)\n",
    "    write_mode = 'w' if counter == 0 else 'a'\n",
    "    df_speakers.to_csv(FILE_NEWSPAPER_SPEAKER,header = add_header,index=False, mode=write_mode,compression='bz2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c6f8dc",
   "metadata": {},
   "source": [
    "### 2) For each speaker preprocess its name and compute the number of times it appeared in the articles\n",
    "For now, the certainty probability of a quote's speaker being correct is not taken into account and every (newspaper,speaker) pair is kept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b7a3510",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_speaker(speaker):\n",
    "    #Lower case the names and remove all non alpha numeric characters\n",
    "    new_name = speaker.lower()\n",
    "    new_name = re.sub(r'[^A-Za-z0-9 ]+', '', new_name)\n",
    "    return new_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb06a6eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The previous unique speaker count was 218415 and the new unique speaker count is 212147\n",
      "This correspond to a 2.87% reduction\n"
     ]
    }
   ],
   "source": [
    "#The file is small enough to be loaded in memory\n",
    "df = pd.read_csv(FILE_NEWSPAPER_SPEAKER,compression='bz2')\n",
    "\n",
    "previous_speaker_count = len(df['speaker'].unique())\n",
    "df['speaker'] = df['speaker'].apply(process_speaker)\n",
    "processed_speaker_count = len(df['speaker'].unique())\n",
    "\n",
    "print(f'The previous unique speaker count was {previous_speaker_count} and the new unique speaker count is {processed_speaker_count}')\n",
    "print(f'This correspond to a {(previous_speaker_count-processed_speaker_count)/previous_speaker_count:.2%} reduction')\n",
    "\n",
    "#Save to memory\n",
    "df.to_csv(FILE_NEWSPAPER_SPEAKER,header = True,index=False, mode='w',compression='bz2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d0a29855",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>newspaper</th>\n",
       "      <th>speaker</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1011now</td>\n",
       "      <td>adam morfeld</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1011now</td>\n",
       "      <td>adam schiff</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1011now</td>\n",
       "      <td>adrian smith</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1011now</td>\n",
       "      <td>alexandra brown</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1011now</td>\n",
       "      <td>alfonso morales</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2434405</th>\n",
       "      <td>zigwheels</td>\n",
       "      <td>srinivas reddy</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2434406</th>\n",
       "      <td>zigwheels</td>\n",
       "      <td>toby price</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2434407</th>\n",
       "      <td>zigwheels</td>\n",
       "      <td>yash aradhya</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2434408</th>\n",
       "      <td>zip06</td>\n",
       "      <td>mike caruso</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2434409</th>\n",
       "      <td>zip06</td>\n",
       "      <td>none</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2434410 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         newspaper          speaker  count\n",
       "0          1011now     adam morfeld      4\n",
       "1          1011now      adam schiff      2\n",
       "2          1011now     adrian smith      2\n",
       "3          1011now  alexandra brown      1\n",
       "4          1011now  alfonso morales      1\n",
       "...            ...              ...    ...\n",
       "2434405  zigwheels   srinivas reddy      1\n",
       "2434406  zigwheels       toby price      1\n",
       "2434407  zigwheels     yash aradhya      1\n",
       "2434408      zip06      mike caruso     16\n",
       "2434409      zip06             none      2\n",
       "\n",
       "[2434410 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newspaper_speaker_count = df.groupby(['newspaper','speaker'],as_index=False).count()\\\n",
    "                            .rename(columns = {'proba':'count'})\n",
    "newspaper_speaker_count.to_csv(FILE_NEWSPAPER_SPEAKER_COUNT,header = True,index=False, mode='w',compression='bz2')\n",
    "newspaper_speaker_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75991850",
   "metadata": {},
   "source": [
    "### 3) Create newspaper set and indexes\n",
    "We create the sorted set of newspapers and the indexes to link the matrix entries to newspapers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f4983dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "newspapers = set(newspaper_speaker_count.newspaper)\n",
    "newspapers = sorted(list(newspapers))\n",
    "\n",
    "# Newspaper name => row index\n",
    "newspaper_to_index = {s:i for i,s in enumerate(newspapers)}\n",
    "with open(PICKLE_NEWSPAPER_TO_INDEX, 'wb') as handle:\n",
    "    pickle.dump(newspaper_to_index, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "# Row index => newspaper name\n",
    "index_to_newspaper = {i:s for i,s in enumerate(newspapers)}\n",
    "with open(PICKLE_INDEX_TO_NEWSPAPER, 'wb') as handle:\n",
    "    pickle.dump(index_to_newspaper, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60405eaa",
   "metadata": {},
   "source": [
    "### 4) Create speaker set and indexes\n",
    "We create the sorted set of speakers and the indexes to link the matrix entries to speakers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "61b6656f",
   "metadata": {},
   "outputs": [],
   "source": [
    "speakers = set(newspaper_speaker_count.speaker)\n",
    "speakers.remove(\"none\")\n",
    "speakers = sorted(list(speakers))\n",
    "\n",
    "speaker_to_index = {s:i for i,s in enumerate(speakers)}\n",
    "index_to_speaker = {i:s for i,s in enumerate(speakers)}\n",
    "\n",
    "    \n",
    "with open(PICKLE_SPEAKER_TO_INDEX, 'wb') as handle:\n",
    "    pickle.dump(speaker_to_index, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open(PICKLE_INDEX_TO_SPEAKER, 'wb') as handle:\n",
    "    pickle.dump(index_to_speaker, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f4271f",
   "metadata": {},
   "source": [
    "### 5) Create frequency matrix\n",
    "We generate a frequency < newspaper x speaker > matrix: entry (i,j) is the number of time speaker j appears in newspaper i."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e7792d88",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "80000\n",
      "90000\n",
      "100000\n",
      "110000\n",
      "120000\n",
      "130000\n",
      "140000\n",
      "150000\n",
      "160000\n",
      "170000\n",
      "180000\n",
      "190000\n",
      "200000\n",
      "210000\n",
      "220000\n",
      "230000\n",
      "240000\n",
      "250000\n",
      "260000\n",
      "270000\n",
      "280000\n",
      "290000\n",
      "300000\n",
      "310000\n",
      "320000\n",
      "330000\n",
      "340000\n",
      "350000\n",
      "360000\n",
      "370000\n",
      "380000\n",
      "390000\n",
      "400000\n",
      "410000\n",
      "420000\n",
      "430000\n",
      "440000\n",
      "450000\n",
      "460000\n",
      "470000\n",
      "480000\n",
      "490000\n",
      "500000\n",
      "510000\n",
      "520000\n",
      "530000\n",
      "540000\n",
      "550000\n",
      "560000\n",
      "570000\n",
      "580000\n",
      "590000\n",
      "600000\n",
      "610000\n",
      "620000\n",
      "630000\n",
      "640000\n",
      "650000\n",
      "660000\n",
      "670000\n",
      "680000\n",
      "690000\n",
      "700000\n",
      "710000\n",
      "720000\n",
      "730000\n",
      "740000\n",
      "750000\n",
      "760000\n",
      "770000\n",
      "780000\n",
      "790000\n",
      "800000\n",
      "810000\n",
      "820000\n",
      "830000\n",
      "840000\n",
      "850000\n",
      "860000\n",
      "870000\n",
      "880000\n",
      "890000\n",
      "900000\n",
      "910000\n",
      "920000\n",
      "930000\n",
      "940000\n",
      "950000\n",
      "960000\n",
      "970000\n",
      "980000\n",
      "990000\n",
      "1000000\n",
      "1010000\n",
      "1020000\n",
      "1030000\n",
      "1040000\n",
      "1050000\n",
      "1060000\n",
      "1070000\n",
      "1080000\n",
      "1090000\n",
      "1100000\n",
      "1110000\n",
      "1120000\n",
      "1130000\n",
      "1140000\n",
      "1150000\n",
      "1160000\n",
      "1170000\n",
      "1180000\n",
      "1190000\n",
      "1200000\n",
      "1210000\n",
      "1220000\n",
      "1230000\n",
      "1240000\n",
      "1250000\n",
      "1260000\n",
      "1270000\n",
      "1280000\n",
      "1290000\n",
      "1300000\n",
      "1310000\n",
      "1320000\n",
      "1330000\n",
      "1340000\n",
      "1350000\n",
      "1360000\n",
      "1370000\n",
      "1380000\n",
      "1390000\n",
      "1400000\n",
      "1410000\n",
      "1420000\n",
      "1430000\n",
      "1440000\n",
      "1450000\n",
      "1460000\n",
      "1470000\n",
      "1480000\n",
      "1490000\n",
      "1500000\n",
      "1510000\n",
      "1520000\n",
      "1530000\n",
      "1540000\n",
      "1550000\n",
      "1560000\n",
      "1570000\n",
      "1580000\n",
      "1590000\n",
      "1600000\n",
      "1610000\n",
      "1620000\n",
      "1630000\n",
      "1640000\n",
      "1650000\n",
      "1660000\n",
      "1670000\n",
      "1680000\n",
      "1690000\n",
      "1700000\n",
      "1710000\n",
      "1720000\n",
      "1730000\n",
      "1740000\n",
      "1750000\n",
      "1760000\n",
      "1770000\n",
      "1780000\n",
      "1790000\n",
      "1800000\n",
      "1810000\n",
      "1820000\n",
      "1830000\n",
      "1840000\n",
      "1850000\n",
      "1860000\n",
      "1870000\n",
      "1880000\n",
      "1890000\n",
      "1900000\n",
      "1910000\n",
      "1920000\n",
      "1930000\n",
      "1940000\n",
      "1950000\n",
      "1960000\n",
      "1970000\n",
      "1980000\n",
      "1990000\n",
      "2000000\n",
      "2010000\n",
      "2020000\n",
      "2030000\n",
      "2040000\n",
      "2050000\n",
      "2060000\n",
      "2070000\n",
      "2080000\n",
      "2090000\n",
      "2100000\n",
      "2110000\n",
      "2120000\n",
      "2130000\n",
      "2140000\n",
      "2150000\n",
      "2160000\n",
      "2170000\n",
      "2180000\n",
      "2190000\n",
      "2200000\n",
      "2210000\n",
      "2220000\n",
      "2230000\n",
      "2240000\n",
      "2250000\n",
      "2260000\n",
      "2270000\n",
      "2280000\n",
      "2290000\n",
      "2300000\n",
      "2310000\n",
      "2320000\n",
      "2330000\n",
      "2340000\n",
      "2350000\n",
      "2360000\n",
      "2370000\n",
      "2380000\n",
      "2390000\n",
      "2400000\n",
      "2410000\n",
      "2420000\n",
      "2430000\n"
     ]
    }
   ],
   "source": [
    "newspaper_speaker_frequency_matrix = dok_matrix((len(newspapers), len(speakers)), dtype=np.uint32)\n",
    "\n",
    "df_newspaper_speaker_count_not_none = newspaper_speaker_count[newspaper_speaker_count['speaker']!='none']\n",
    "for index, row in df_newspaper_speaker_count_not_none.iterrows():\n",
    "    if index % 10000==0:\n",
    "        print(index)\n",
    "    index_speaker = speaker_to_index[row['speaker']]\n",
    "    index_newspaper = newspaper_to_index[row['newspaper']]\n",
    "    newspaper_speaker_frequency_matrix[index_newspaper, index_speaker] = row[\"count\"]\n",
    "    \n",
    "newspaper_speaker_frequency_csr = newspaper_speaker_frequency_matrix.tocsr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a15615",
   "metadata": {},
   "source": [
    "### 6) Create TF-IDF matrix and write it to a file\n",
    "Transform the frequency matrix into a TF-IDF matrix. Each row is normalised and each column is scaled by proportionnaly to the number of newspaper in which the speaker is quoted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "39a84ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = TfidfTransformer()\n",
    "newspaper_speaker_tfidf = transformer.fit_transform(newspaper_speaker_frequency_csr)\n",
    "sparse.save_npz(FILE_NEWSPAPER_SPEAKER_TFIDF, newspaper_speaker_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41cb97e6",
   "metadata": {},
   "source": [
    "## Quotes pipeline\n",
    "We create a < newspaper, token > TFIDF matrix from the quotes.  \n",
    "1) Extract newspaper and token from the quotes    \n",
    "2) Create token vocabulary and indexes  \n",
    "3) Create frequency matrix  \n",
    "4) Create TF-IDF matrix and write it to a file  \n",
    "\n",
    "### 1) Extract newspapers and tokens from the quotes \n",
    "\n",
    "We read all the quotes, preprocess them, create token, write a file <newspaper: tokens> (one line per quote)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ad78b580",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(quote):\n",
    "    \"\"\"\n",
    "    Lower first letter of the sentence\n",
    "    Remove number\n",
    "    Tokenize\n",
    "    Remove stop words and words of len = 1\n",
    "    Lemmatize\n",
    "    Remove stop words and words of len = 1 (again)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Lower first word of the sentence\n",
    "    lower_first_word = lambda tab: \" \".join([tab[0].lower()] + tab[1:])\n",
    "    quote = \" \".join([lower_first_word(sentence.split(\" \")) for sentence in quote.split(\".\")])\n",
    "    \n",
    "    #Remove Numbers\n",
    "    quote = re.sub(r'\\d+', '', quote) \n",
    "\n",
    "    # Tokenize\n",
    "    tokenizer = nltk.RegexpTokenizer(r\"\\w+\")\n",
    "    word_tokens = tokenizer.tokenize(quote)\n",
    "            \n",
    "    remove_stop_words = lambda wt: [w for w in wt if not w in en_stopwords and len(w) > 1]\n",
    "    # Remove stop words and single letters\n",
    "    word_tokens = remove_stop_words(word_tokens)\n",
    "\n",
    "    # Lemmatize\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    word_tokens = [lemmatizer.lemmatize(w) for w in word_tokens]\n",
    "    \n",
    "    # Remove stop words and single letters\n",
    "    word_tokens = remove_stop_words(word_tokens)\n",
    "        \n",
    "    return word_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9deabcd0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk: 0\n",
      "Chunk: 1\n",
      "Chunk: 2\n",
      "Chunk: 3\n",
      "Chunk: 4\n",
      "Chunk: 5\n",
      "Chunk: 6\n",
      "Chunk: 7\n",
      "Chunk: 8\n",
      "Chunk: 9\n",
      "Chunk: 10\n",
      "Chunk: 11\n",
      "Chunk: 12\n",
      "Chunk: 13\n",
      "Chunk: 14\n",
      "Chunk: 15\n",
      "Chunk: 16\n",
      "Chunk: 17\n",
      "Chunk: 18\n",
      "Chunk: 19\n",
      "Chunk: 20\n",
      "Chunk: 21\n",
      "Chunk: 22\n",
      "Chunk: 23\n",
      "Chunk: 24\n",
      "Chunk: 25\n",
      "Chunk: 26\n",
      "Chunk: 27\n",
      "Chunk: 28\n",
      "Chunk: 29\n",
      "Chunk: 30\n",
      "Chunk: 31\n",
      "Chunk: 32\n",
      "Chunk: 33\n",
      "Chunk: 34\n",
      "Chunk: 35\n",
      "Chunk: 36\n",
      "Chunk: 37\n",
      "Chunk: 38\n",
      "Chunk: 39\n",
      "Chunk: 40\n",
      "Chunk: 41\n",
      "Chunk: 42\n",
      "Chunk: 43\n",
      "Chunk: 44\n",
      "Chunk: 45\n",
      "Chunk: 46\n",
      "Chunk: 47\n",
      "Chunk: 48\n",
      "Chunk: 49\n",
      "Chunk: 50\n",
      "Chunk: 51\n",
      "Chunk: 52\n",
      "Chunk: 53\n",
      "Chunk: 54\n",
      "Chunk: 55\n",
      "Chunk: 56\n",
      "Chunk: 57\n",
      "Chunk: 58\n",
      "Chunk: 59\n",
      "Chunk: 60\n",
      "Chunk: 61\n",
      "Chunk: 62\n",
      "Chunk: 63\n",
      "Chunk: 64\n",
      "Chunk: 65\n",
      "Chunk: 66\n",
      "Chunk: 67\n",
      "Chunk: 68\n",
      "Chunk: 69\n",
      "Chunk: 70\n",
      "Chunk: 71\n",
      "Chunk: 72\n",
      "Chunk: 73\n",
      "Chunk: 74\n",
      "Chunk: 75\n",
      "Chunk: 76\n",
      "Chunk: 77\n",
      "Chunk: 78\n",
      "Chunk: 79\n",
      "Chunk: 80\n",
      "Chunk: 81\n",
      "Chunk: 82\n",
      "Chunk: 83\n",
      "Chunk: 84\n",
      "Chunk: 85\n",
      "Chunk: 86\n",
      "Chunk: 87\n",
      "Chunk: 88\n",
      "Chunk: 89\n",
      "Chunk: 90\n",
      "Chunk: 91\n",
      "Chunk: 92\n",
      "Chunk: 93\n",
      "Chunk: 94\n",
      "Chunk: 95\n",
      "Chunk: 96\n",
      "Chunk: 97\n",
      "Chunk: 98\n",
      "Chunk: 99\n",
      "Chunk: 100\n",
      "Chunk: 101\n",
      "Chunk: 102\n",
      "Chunk: 103\n",
      "Chunk: 104\n",
      "Chunk: 105\n",
      "Chunk: 106\n",
      "Chunk: 107\n",
      "Chunk: 108\n",
      "Chunk: 109\n",
      "Chunk: 110\n",
      "Chunk: 111\n",
      "Chunk: 112\n",
      "Chunk: 113\n",
      "Chunk: 114\n",
      "Chunk: 115\n",
      "Chunk: 116\n",
      "Chunk: 117\n",
      "Chunk: 118\n",
      "Chunk: 119\n",
      "Chunk: 120\n",
      "Chunk: 121\n",
      "Chunk: 122\n",
      "Chunk: 123\n",
      "Chunk: 124\n",
      "Chunk: 125\n",
      "Chunk: 126\n",
      "Chunk: 127\n",
      "Chunk: 128\n",
      "Chunk: 129\n",
      "Chunk: 130\n",
      "Chunk: 131\n",
      "Chunk: 132\n",
      "Chunk: 133\n",
      "Chunk: 134\n",
      "Chunk: 135\n",
      "Chunk: 136\n",
      "Chunk: 137\n",
      "Chunk: 138\n",
      "Chunk: 139\n",
      "Chunk: 140\n",
      "Chunk: 141\n",
      "Chunk: 142\n",
      "Chunk: 143\n",
      "Chunk: 144\n",
      "Chunk: 145\n",
      "Chunk: 146\n",
      "Chunk: 147\n",
      "Chunk: 148\n",
      "Chunk: 149\n",
      "Chunk: 150\n",
      "Chunk: 151\n",
      "Chunk: 152\n",
      "Chunk: 153\n",
      "Chunk: 154\n",
      "Chunk: 155\n",
      "Chunk: 156\n",
      "Chunk: 157\n",
      "Chunk: 158\n",
      "Chunk: 159\n",
      "Chunk: 160\n",
      "Chunk: 161\n",
      "Chunk: 162\n",
      "Chunk: 163\n",
      "Chunk: 164\n",
      "Chunk: 165\n",
      "Chunk: 166\n",
      "Chunk: 167\n",
      "Chunk: 168\n",
      "Chunk: 169\n",
      "Chunk: 170\n",
      "Chunk: 171\n",
      "Chunk: 172\n",
      "Chunk: 173\n",
      "Chunk: 174\n",
      "Chunk: 175\n",
      "Chunk: 176\n",
      "Chunk: 177\n",
      "Chunk: 178\n",
      "Chunk: 179\n",
      "Chunk: 180\n",
      "Chunk: 181\n",
      "Chunk: 182\n",
      "Chunk: 183\n",
      "Chunk: 184\n",
      "Chunk: 185\n",
      "Chunk: 186\n",
      "Chunk: 187\n",
      "Chunk: 188\n",
      "Chunk: 189\n",
      "Chunk: 190\n",
      "Chunk: 191\n",
      "Chunk: 192\n",
      "Chunk: 193\n",
      "Chunk: 194\n",
      "Chunk: 195\n",
      "Chunk: 196\n",
      "Chunk: 197\n",
      "Chunk: 198\n",
      "Chunk: 199\n",
      "Chunk: 200\n",
      "Chunk: 201\n",
      "Chunk: 202\n",
      "Chunk: 203\n",
      "Chunk: 204\n",
      "Chunk: 205\n",
      "Chunk: 206\n",
      "Chunk: 207\n",
      "Chunk: 208\n",
      "Chunk: 209\n",
      "Chunk: 210\n",
      "Chunk: 211\n",
      "Chunk: 212\n",
      "Chunk: 213\n",
      "Chunk: 214\n",
      "Chunk: 215\n",
      "Chunk: 216\n",
      "Chunk: 217\n",
      "Chunk: 218\n",
      "Chunk: 219\n",
      "Chunk: 220\n",
      "Chunk: 221\n",
      "Chunk: 222\n",
      "Chunk: 223\n",
      "Chunk: 224\n",
      "Chunk: 225\n",
      "Chunk: 226\n",
      "Chunk: 227\n",
      "Chunk: 228\n",
      "Chunk: 229\n",
      "Chunk: 230\n",
      "Chunk: 231\n",
      "Chunk: 232\n",
      "Chunk: 233\n",
      "Chunk: 234\n",
      "Chunk: 235\n",
      "Chunk: 236\n",
      "Chunk: 237\n",
      "Chunk: 238\n",
      "Chunk: 239\n",
      "Chunk: 240\n",
      "Chunk: 241\n",
      "Chunk: 242\n",
      "Chunk: 243\n",
      "Chunk: 244\n",
      "Chunk: 245\n",
      "Chunk: 246\n",
      "Chunk: 247\n",
      "Chunk: 248\n",
      "Chunk: 249\n",
      "Chunk: 250\n",
      "Chunk: 251\n",
      "Chunk: 252\n",
      "Chunk: 253\n",
      "Chunk: 254\n",
      "Chunk: 255\n",
      "Chunk: 256\n",
      "Chunk: 257\n",
      "Chunk: 258\n",
      "Chunk: 259\n",
      "Chunk: 260\n",
      "Chunk: 261\n",
      "Chunk: 262\n",
      "Chunk: 263\n",
      "Chunk: 264\n",
      "Chunk: 265\n",
      "Chunk: 266\n",
      "Chunk: 267\n",
      "Chunk: 268\n",
      "Chunk: 269\n",
      "Chunk: 270\n",
      "Chunk: 271\n",
      "Chunk: 272\n",
      "Chunk: 273\n",
      "Chunk: 274\n",
      "Chunk: 275\n",
      "Chunk: 276\n",
      "Chunk: 277\n",
      "Chunk: 278\n",
      "Chunk: 279\n",
      "Chunk: 280\n",
      "Chunk: 281\n",
      "Chunk: 282\n",
      "Chunk: 283\n",
      "Chunk: 284\n",
      "Chunk: 285\n",
      "Chunk: 286\n",
      "Chunk: 287\n",
      "Chunk: 288\n",
      "Chunk: 289\n",
      "Chunk: 290\n",
      "Chunk: 291\n",
      "Chunk: 292\n",
      "Chunk: 293\n",
      "Chunk: 294\n",
      "Chunk: 295\n",
      "Chunk: 296\n",
      "Chunk: 297\n",
      "Chunk: 298\n",
      "Chunk: 299\n",
      "Chunk: 300\n",
      "Chunk: 301\n",
      "Chunk: 302\n",
      "Chunk: 303\n",
      "Chunk: 304\n",
      "Chunk: 305\n",
      "Chunk: 306\n",
      "Chunk: 307\n",
      "Chunk: 308\n",
      "Chunk: 309\n",
      "Chunk: 310\n",
      "Chunk: 311\n",
      "Chunk: 312\n",
      "Chunk: 313\n",
      "Chunk: 314\n",
      "Chunk: 315\n",
      "Chunk: 316\n",
      "Chunk: 317\n",
      "Chunk: 318\n",
      "Chunk: 319\n",
      "Chunk: 320\n",
      "Chunk: 321\n",
      "Chunk: 322\n",
      "Chunk: 323\n",
      "Chunk: 324\n",
      "Chunk: 325\n",
      "Chunk: 326\n",
      "Chunk: 327\n",
      "Chunk: 328\n",
      "Chunk: 329\n",
      "Chunk: 330\n",
      "Chunk: 331\n",
      "Chunk: 332\n",
      "Chunk: 333\n",
      "Chunk: 334\n",
      "Chunk: 335\n",
      "Chunk: 336\n",
      "Chunk: 337\n",
      "Chunk: 338\n",
      "Chunk: 339\n",
      "Chunk: 340\n",
      "Chunk: 341\n",
      "Chunk: 342\n",
      "Chunk: 343\n",
      "Chunk: 344\n",
      "Chunk: 345\n",
      "Chunk: 346\n",
      "Chunk: 347\n",
      "Chunk: 348\n",
      "Chunk: 349\n",
      "Chunk: 350\n",
      "Chunk: 351\n",
      "Chunk: 352\n",
      "Chunk: 353\n",
      "Chunk: 354\n",
      "Chunk: 355\n",
      "Chunk: 356\n",
      "Chunk: 357\n",
      "Chunk: 358\n",
      "Chunk: 359\n",
      "Chunk: 360\n",
      "Chunk: 361\n",
      "Chunk: 362\n",
      "Chunk: 363\n",
      "Chunk: 364\n",
      "Chunk: 365\n",
      "Chunk: 366\n",
      "Chunk: 367\n",
      "Chunk: 368\n",
      "Chunk: 369\n",
      "Chunk: 370\n",
      "Chunk: 371\n",
      "Chunk: 372\n",
      "Chunk: 373\n",
      "Chunk: 374\n",
      "Chunk: 375\n",
      "Chunk: 376\n",
      "Chunk: 377\n",
      "Chunk: 378\n",
      "Chunk: 379\n",
      "Chunk: 380\n",
      "Chunk: 381\n",
      "Chunk: 382\n",
      "Chunk: 383\n",
      "Chunk: 384\n",
      "Chunk: 385\n",
      "Chunk: 386\n",
      "Chunk: 387\n",
      "Chunk: 388\n",
      "Chunk: 389\n",
      "Chunk: 390\n",
      "Chunk: 391\n",
      "Chunk: 392\n",
      "Chunk: 393\n",
      "Chunk: 394\n",
      "Chunk: 395\n",
      "Chunk: 396\n",
      "Chunk: 397\n",
      "Chunk: 398\n",
      "Chunk: 399\n",
      "Chunk: 400\n",
      "Chunk: 401\n",
      "Chunk: 402\n",
      "Chunk: 403\n",
      "Chunk: 404\n",
      "Chunk: 405\n",
      "Chunk: 406\n",
      "Chunk: 407\n",
      "Chunk: 408\n",
      "Chunk: 409\n",
      "Chunk: 410\n",
      "Chunk: 411\n",
      "Chunk: 412\n",
      "Chunk: 413\n",
      "Chunk: 414\n",
      "Chunk: 415\n",
      "Chunk: 416\n",
      "Chunk: 417\n",
      "Chunk: 418\n",
      "Chunk: 419\n",
      "Chunk: 420\n",
      "Chunk: 421\n",
      "Chunk: 422\n",
      "Chunk: 423\n",
      "Chunk: 424\n",
      "Chunk: 425\n",
      "Chunk: 426\n",
      "Chunk: 427\n",
      "Chunk: 428\n",
      "Chunk: 429\n",
      "Chunk: 430\n",
      "Chunk: 431\n",
      "Chunk: 432\n",
      "Chunk: 433\n",
      "Chunk: 434\n",
      "Chunk: 435\n",
      "Chunk: 436\n",
      "Chunk: 437\n",
      "Chunk: 438\n",
      "Chunk: 439\n",
      "Chunk: 440\n",
      "Chunk: 441\n",
      "Chunk: 442\n",
      "Chunk: 443\n",
      "Chunk: 444\n",
      "Chunk: 445\n",
      "Chunk: 446\n",
      "Chunk: 447\n",
      "Chunk: 448\n",
      "Chunk: 449\n",
      "Chunk: 450\n",
      "Chunk: 451\n",
      "Chunk: 452\n",
      "Chunk: 453\n",
      "Chunk: 454\n",
      "Chunk: 455\n",
      "Chunk: 456\n",
      "Chunk: 457\n",
      "Chunk: 458\n",
      "Chunk: 459\n",
      "Chunk: 460\n",
      "Chunk: 461\n",
      "Chunk: 462\n",
      "Chunk: 463\n",
      "Chunk: 464\n",
      "Chunk: 465\n",
      "Chunk: 466\n",
      "Chunk: 467\n",
      "Chunk: 468\n",
      "Chunk: 469\n",
      "Chunk: 470\n",
      "Chunk: 471\n",
      "Chunk: 472\n",
      "Chunk: 473\n",
      "Chunk: 474\n",
      "Chunk: 475\n",
      "Chunk: 476\n",
      "Chunk: 477\n",
      "Chunk: 478\n",
      "Chunk: 479\n",
      "Chunk: 480\n",
      "Chunk: 481\n",
      "Chunk: 482\n",
      "Chunk: 483\n",
      "Chunk: 484\n",
      "Chunk: 485\n",
      "Chunk: 486\n",
      "Chunk: 487\n",
      "Chunk: 488\n",
      "Chunk: 489\n",
      "Chunk: 490\n",
      "Chunk: 491\n",
      "Chunk: 492\n",
      "Chunk: 493\n",
      "Chunk: 494\n",
      "Chunk: 495\n",
      "Chunk: 496\n",
      "Chunk: 497\n",
      "Chunk: 498\n",
      "Chunk: 499\n",
      "Chunk: 500\n",
      "Chunk: 501\n",
      "Chunk: 502\n",
      "Chunk: 503\n",
      "Chunk: 504\n",
      "Chunk: 505\n",
      "Chunk: 506\n",
      "Chunk: 507\n",
      "Chunk: 508\n",
      "Chunk: 509\n",
      "Chunk: 510\n",
      "Chunk: 511\n",
      "Chunk: 512\n",
      "Chunk: 513\n",
      "Chunk: 514\n",
      "Chunk: 515\n",
      "Chunk: 516\n",
      "Chunk: 517\n",
      "Chunk: 518\n",
      "Chunk: 519\n",
      "Chunk: 520\n",
      "Chunk: 521\n",
      "Chunk: 522\n",
      "Chunk: 523\n",
      "Chunk: 524\n"
     ]
    }
   ],
   "source": [
    "json_reader = pd.read_json(FILE_QUOTES,lines=True,chunksize=10_000,compression='bz2') \n",
    "\n",
    "for (counter, df_chunk) in enumerate(json_reader):\n",
    "    print(f\"Chunk: {counter}\")\n",
    "    \n",
    "    # Preprocess all quotes\n",
    "    df_chunk[\"tokens\"] = df_chunk[\"quotation\"].apply(preprocess)\n",
    "    \n",
    "    # Transform url to newpaper acronyme\n",
    "    df_chunk[\"newspapers\"] = df_chunk[\"urls\"].apply(lambda ln: [extract_domain(n) for n in ln])\n",
    "    \n",
    "    # Row = [newspaper list] [preprocessed quotation]\n",
    "    df_quotes = df_chunk[[\"newspapers\", \"tokens\"]]\n",
    "\n",
    "    # Write result chunk by chunk in a csv compressed file\n",
    "    add_header = (counter==0)\n",
    "    write_mode = 'w' if counter == 0 else 'a'\n",
    "    df_quotes.to_csv(FILE_NEWSPAPER_TOKEN,header = add_header,index=False, mode=write_mode,compression='bz2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec0c6c8",
   "metadata": {},
   "source": [
    "### 2) Create token vocabulary and indexes\n",
    "We create the sorted set of tokens and the indexes to link the matrix entries to tokens.\n",
    "We iterate over all the quotes to create the vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f93c34cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk: 0\n",
      "Chunk: 1\n",
      "Chunk: 2\n",
      "Chunk: 3\n",
      "Chunk: 4\n",
      "Chunk: 5\n",
      "Chunk: 6\n",
      "Chunk: 7\n",
      "Chunk: 8\n",
      "Chunk: 9\n",
      "Chunk: 10\n",
      "Chunk: 11\n",
      "Chunk: 12\n",
      "Chunk: 13\n",
      "Chunk: 14\n",
      "Chunk: 15\n",
      "Chunk: 16\n",
      "Chunk: 17\n",
      "Chunk: 18\n",
      "Chunk: 19\n",
      "Chunk: 20\n",
      "Chunk: 21\n",
      "Chunk: 22\n",
      "Chunk: 23\n",
      "Chunk: 24\n",
      "Chunk: 25\n",
      "Chunk: 26\n",
      "Chunk: 27\n",
      "Chunk: 28\n",
      "Chunk: 29\n",
      "Chunk: 30\n",
      "Chunk: 31\n",
      "Chunk: 32\n",
      "Chunk: 33\n",
      "Chunk: 34\n",
      "Chunk: 35\n",
      "Chunk: 36\n",
      "Chunk: 37\n",
      "Chunk: 38\n",
      "Chunk: 39\n",
      "Chunk: 40\n",
      "Chunk: 41\n",
      "Chunk: 42\n",
      "Chunk: 43\n",
      "Chunk: 44\n",
      "Chunk: 45\n",
      "Chunk: 46\n",
      "Chunk: 47\n",
      "Chunk: 48\n",
      "Chunk: 49\n",
      "Chunk: 50\n",
      "Chunk: 51\n",
      "Chunk: 52\n",
      "Chunk: 53\n",
      "Chunk: 54\n",
      "Chunk: 55\n",
      "Chunk: 56\n",
      "Chunk: 57\n",
      "Chunk: 58\n",
      "Chunk: 59\n",
      "Chunk: 60\n",
      "Chunk: 61\n",
      "Chunk: 62\n",
      "Chunk: 63\n",
      "Chunk: 64\n",
      "Chunk: 65\n",
      "Chunk: 66\n",
      "Chunk: 67\n",
      "Chunk: 68\n",
      "Chunk: 69\n",
      "Chunk: 70\n",
      "Chunk: 71\n",
      "Chunk: 72\n",
      "Chunk: 73\n",
      "Chunk: 74\n",
      "Chunk: 75\n",
      "Chunk: 76\n",
      "Chunk: 77\n",
      "Chunk: 78\n",
      "Chunk: 79\n",
      "Chunk: 80\n",
      "Chunk: 81\n",
      "Chunk: 82\n",
      "Chunk: 83\n",
      "Chunk: 84\n",
      "Chunk: 85\n",
      "Chunk: 86\n",
      "Chunk: 87\n",
      "Chunk: 88\n",
      "Chunk: 89\n",
      "Chunk: 90\n",
      "Chunk: 91\n",
      "Chunk: 92\n",
      "Chunk: 93\n",
      "Chunk: 94\n",
      "Chunk: 95\n",
      "Chunk: 96\n",
      "Chunk: 97\n",
      "Chunk: 98\n",
      "Chunk: 99\n",
      "Chunk: 100\n",
      "Chunk: 101\n",
      "Chunk: 102\n",
      "Chunk: 103\n",
      "Chunk: 104\n",
      "Chunk: 105\n",
      "Chunk: 106\n",
      "Chunk: 107\n",
      "Chunk: 108\n",
      "Chunk: 109\n",
      "Chunk: 110\n",
      "Chunk: 111\n",
      "Chunk: 112\n",
      "Chunk: 113\n",
      "Chunk: 114\n",
      "Chunk: 115\n",
      "Chunk: 116\n",
      "Chunk: 117\n",
      "Chunk: 118\n",
      "Chunk: 119\n",
      "Chunk: 120\n",
      "Chunk: 121\n",
      "Chunk: 122\n",
      "Chunk: 123\n",
      "Chunk: 124\n",
      "Chunk: 125\n",
      "Chunk: 126\n",
      "Chunk: 127\n",
      "Chunk: 128\n",
      "Chunk: 129\n",
      "Chunk: 130\n",
      "Chunk: 131\n",
      "Chunk: 132\n",
      "Chunk: 133\n",
      "Chunk: 134\n",
      "Chunk: 135\n",
      "Chunk: 136\n",
      "Chunk: 137\n",
      "Chunk: 138\n",
      "Chunk: 139\n",
      "Chunk: 140\n",
      "Chunk: 141\n",
      "Chunk: 142\n",
      "Chunk: 143\n",
      "Chunk: 144\n",
      "Chunk: 145\n",
      "Chunk: 146\n",
      "Chunk: 147\n",
      "Chunk: 148\n",
      "Chunk: 149\n",
      "Chunk: 150\n",
      "Chunk: 151\n",
      "Chunk: 152\n",
      "Chunk: 153\n",
      "Chunk: 154\n",
      "Chunk: 155\n",
      "Chunk: 156\n",
      "Chunk: 157\n",
      "Chunk: 158\n",
      "Chunk: 159\n",
      "Chunk: 160\n",
      "Chunk: 161\n",
      "Chunk: 162\n",
      "Chunk: 163\n",
      "Chunk: 164\n",
      "Chunk: 165\n",
      "Chunk: 166\n",
      "Chunk: 167\n",
      "Chunk: 168\n",
      "Chunk: 169\n",
      "Chunk: 170\n",
      "Chunk: 171\n",
      "Chunk: 172\n",
      "Chunk: 173\n",
      "Chunk: 174\n",
      "Chunk: 175\n",
      "Chunk: 176\n",
      "Chunk: 177\n",
      "Chunk: 178\n",
      "Chunk: 179\n",
      "Chunk: 180\n",
      "Chunk: 181\n",
      "Chunk: 182\n",
      "Chunk: 183\n",
      "Chunk: 184\n",
      "Chunk: 185\n",
      "Chunk: 186\n",
      "Chunk: 187\n",
      "Chunk: 188\n",
      "Chunk: 189\n",
      "Chunk: 190\n",
      "Chunk: 191\n",
      "Chunk: 192\n",
      "Chunk: 193\n",
      "Chunk: 194\n",
      "Chunk: 195\n",
      "Chunk: 196\n",
      "Chunk: 197\n",
      "Chunk: 198\n",
      "Chunk: 199\n",
      "Chunk: 200\n",
      "Chunk: 201\n",
      "Chunk: 202\n",
      "Chunk: 203\n",
      "Chunk: 204\n",
      "Chunk: 205\n",
      "Chunk: 206\n",
      "Chunk: 207\n",
      "Chunk: 208\n",
      "Chunk: 209\n",
      "Chunk: 210\n",
      "Chunk: 211\n",
      "Chunk: 212\n",
      "Chunk: 213\n",
      "Chunk: 214\n",
      "Chunk: 215\n",
      "Chunk: 216\n",
      "Chunk: 217\n",
      "Chunk: 218\n",
      "Chunk: 219\n",
      "Chunk: 220\n",
      "Chunk: 221\n",
      "Chunk: 222\n",
      "Chunk: 223\n",
      "Chunk: 224\n",
      "Chunk: 225\n",
      "Chunk: 226\n",
      "Chunk: 227\n",
      "Chunk: 228\n",
      "Chunk: 229\n",
      "Chunk: 230\n",
      "Chunk: 231\n",
      "Chunk: 232\n",
      "Chunk: 233\n",
      "Chunk: 234\n",
      "Chunk: 235\n",
      "Chunk: 236\n",
      "Chunk: 237\n",
      "Chunk: 238\n",
      "Chunk: 239\n",
      "Chunk: 240\n",
      "Chunk: 241\n",
      "Chunk: 242\n",
      "Chunk: 243\n",
      "Chunk: 244\n",
      "Chunk: 245\n",
      "Chunk: 246\n",
      "Chunk: 247\n",
      "Chunk: 248\n",
      "Chunk: 249\n",
      "Chunk: 250\n",
      "Chunk: 251\n",
      "Chunk: 252\n",
      "Chunk: 253\n",
      "Chunk: 254\n",
      "Chunk: 255\n",
      "Chunk: 256\n",
      "Chunk: 257\n",
      "Chunk: 258\n",
      "Chunk: 259\n",
      "Chunk: 260\n",
      "Chunk: 261\n",
      "Chunk: 262\n",
      "Chunk: 263\n",
      "Chunk: 264\n",
      "Chunk: 265\n",
      "Chunk: 266\n",
      "Chunk: 267\n",
      "Chunk: 268\n",
      "Chunk: 269\n",
      "Chunk: 270\n",
      "Chunk: 271\n",
      "Chunk: 272\n",
      "Chunk: 273\n",
      "Chunk: 274\n",
      "Chunk: 275\n",
      "Chunk: 276\n",
      "Chunk: 277\n",
      "Chunk: 278\n",
      "Chunk: 279\n",
      "Chunk: 280\n",
      "Chunk: 281\n",
      "Chunk: 282\n",
      "Chunk: 283\n",
      "Chunk: 284\n",
      "Chunk: 285\n",
      "Chunk: 286\n",
      "Chunk: 287\n",
      "Chunk: 288\n",
      "Chunk: 289\n",
      "Chunk: 290\n",
      "Chunk: 291\n",
      "Chunk: 292\n",
      "Chunk: 293\n",
      "Chunk: 294\n",
      "Chunk: 295\n",
      "Chunk: 296\n",
      "Chunk: 297\n",
      "Chunk: 298\n",
      "Chunk: 299\n",
      "Chunk: 300\n",
      "Chunk: 301\n",
      "Chunk: 302\n",
      "Chunk: 303\n",
      "Chunk: 304\n",
      "Chunk: 305\n",
      "Chunk: 306\n",
      "Chunk: 307\n",
      "Chunk: 308\n",
      "Chunk: 309\n",
      "Chunk: 310\n",
      "Chunk: 311\n",
      "Chunk: 312\n",
      "Chunk: 313\n",
      "Chunk: 314\n",
      "Chunk: 315\n",
      "Chunk: 316\n",
      "Chunk: 317\n",
      "Chunk: 318\n",
      "Chunk: 319\n",
      "Chunk: 320\n",
      "Chunk: 321\n",
      "Chunk: 322\n",
      "Chunk: 323\n",
      "Chunk: 324\n",
      "Chunk: 325\n",
      "Chunk: 326\n",
      "Chunk: 327\n",
      "Chunk: 328\n",
      "Chunk: 329\n",
      "Chunk: 330\n",
      "Chunk: 331\n",
      "Chunk: 332\n",
      "Chunk: 333\n",
      "Chunk: 334\n",
      "Chunk: 335\n",
      "Chunk: 336\n",
      "Chunk: 337\n",
      "Chunk: 338\n",
      "Chunk: 339\n",
      "Chunk: 340\n",
      "Chunk: 341\n",
      "Chunk: 342\n",
      "Chunk: 343\n",
      "Chunk: 344\n",
      "Chunk: 345\n",
      "Chunk: 346\n",
      "Chunk: 347\n",
      "Chunk: 348\n",
      "Chunk: 349\n",
      "Chunk: 350\n",
      "Chunk: 351\n",
      "Chunk: 352\n",
      "Chunk: 353\n",
      "Chunk: 354\n",
      "Chunk: 355\n",
      "Chunk: 356\n",
      "Chunk: 357\n",
      "Chunk: 358\n",
      "Chunk: 359\n",
      "Chunk: 360\n",
      "Chunk: 361\n",
      "Chunk: 362\n",
      "Chunk: 363\n",
      "Chunk: 364\n",
      "Chunk: 365\n",
      "Chunk: 366\n",
      "Chunk: 367\n",
      "Chunk: 368\n",
      "Chunk: 369\n",
      "Chunk: 370\n",
      "Chunk: 371\n",
      "Chunk: 372\n",
      "Chunk: 373\n",
      "Chunk: 374\n",
      "Chunk: 375\n",
      "Chunk: 376\n",
      "Chunk: 377\n",
      "Chunk: 378\n",
      "Chunk: 379\n",
      "Chunk: 380\n",
      "Chunk: 381\n",
      "Chunk: 382\n",
      "Chunk: 383\n",
      "Chunk: 384\n",
      "Chunk: 385\n",
      "Chunk: 386\n",
      "Chunk: 387\n",
      "Chunk: 388\n",
      "Chunk: 389\n",
      "Chunk: 390\n",
      "Chunk: 391\n",
      "Chunk: 392\n",
      "Chunk: 393\n",
      "Chunk: 394\n",
      "Chunk: 395\n",
      "Chunk: 396\n",
      "Chunk: 397\n",
      "Chunk: 398\n",
      "Chunk: 399\n",
      "Chunk: 400\n",
      "Chunk: 401\n",
      "Chunk: 402\n",
      "Chunk: 403\n",
      "Chunk: 404\n",
      "Chunk: 405\n",
      "Chunk: 406\n",
      "Chunk: 407\n",
      "Chunk: 408\n",
      "Chunk: 409\n",
      "Chunk: 410\n",
      "Chunk: 411\n",
      "Chunk: 412\n",
      "Chunk: 413\n",
      "Chunk: 414\n",
      "Chunk: 415\n",
      "Chunk: 416\n",
      "Chunk: 417\n",
      "Chunk: 418\n",
      "Chunk: 419\n",
      "Chunk: 420\n",
      "Chunk: 421\n",
      "Chunk: 422\n",
      "Chunk: 423\n",
      "Chunk: 424\n",
      "Chunk: 425\n",
      "Chunk: 426\n",
      "Chunk: 427\n",
      "Chunk: 428\n",
      "Chunk: 429\n",
      "Chunk: 430\n",
      "Chunk: 431\n",
      "Chunk: 432\n",
      "Chunk: 433\n",
      "Chunk: 434\n",
      "Chunk: 435\n",
      "Chunk: 436\n",
      "Chunk: 437\n",
      "Chunk: 438\n",
      "Chunk: 439\n",
      "Chunk: 440\n",
      "Chunk: 441\n",
      "Chunk: 442\n",
      "Chunk: 443\n",
      "Chunk: 444\n",
      "Chunk: 445\n",
      "Chunk: 446\n",
      "Chunk: 447\n",
      "Chunk: 448\n",
      "Chunk: 449\n",
      "Chunk: 450\n",
      "Chunk: 451\n",
      "Chunk: 452\n",
      "Chunk: 453\n",
      "Chunk: 454\n",
      "Chunk: 455\n",
      "Chunk: 456\n",
      "Chunk: 457\n",
      "Chunk: 458\n",
      "Chunk: 459\n",
      "Chunk: 460\n",
      "Chunk: 461\n",
      "Chunk: 462\n",
      "Chunk: 463\n",
      "Chunk: 464\n",
      "Chunk: 465\n",
      "Chunk: 466\n",
      "Chunk: 467\n",
      "Chunk: 468\n",
      "Chunk: 469\n",
      "Chunk: 470\n",
      "Chunk: 471\n",
      "Chunk: 472\n",
      "Chunk: 473\n",
      "Chunk: 474\n",
      "Chunk: 475\n",
      "Chunk: 476\n",
      "Chunk: 477\n",
      "Chunk: 478\n",
      "Chunk: 479\n",
      "Chunk: 480\n",
      "Chunk: 481\n",
      "Chunk: 482\n",
      "Chunk: 483\n",
      "Chunk: 484\n",
      "Chunk: 485\n",
      "Chunk: 486\n",
      "Chunk: 487\n",
      "Chunk: 488\n",
      "Chunk: 489\n",
      "Chunk: 490\n",
      "Chunk: 491\n",
      "Chunk: 492\n",
      "Chunk: 493\n",
      "Chunk: 494\n",
      "Chunk: 495\n",
      "Chunk: 496\n",
      "Chunk: 497\n",
      "Chunk: 498\n",
      "Chunk: 499\n",
      "Chunk: 500\n",
      "Chunk: 501\n",
      "Chunk: 502\n",
      "Chunk: 503\n",
      "Chunk: 504\n",
      "Chunk: 505\n",
      "Chunk: 506\n",
      "Chunk: 507\n",
      "Chunk: 508\n",
      "Chunk: 509\n",
      "Chunk: 510\n",
      "Chunk: 511\n",
      "Chunk: 512\n",
      "Chunk: 513\n",
      "Chunk: 514\n",
      "Chunk: 515\n",
      "Chunk: 516\n",
      "Chunk: 517\n",
      "Chunk: 518\n",
      "Chunk: 519\n",
      "Chunk: 520\n",
      "Chunk: 521\n",
      "Chunk: 522\n",
      "Chunk: 523\n",
      "Chunk: 524\n"
     ]
    }
   ],
   "source": [
    "csv_reader = pd.read_csv(FILE_NEWSPAPER_TOKEN, chunksize=10_000,compression='bz2', converters={\"newspapers\": ast.literal_eval,\"tokens\":ast.literal_eval}) \n",
    "\n",
    "#Create a Counter of all tokens\n",
    "vocabulary = Counter()\n",
    "\n",
    "for (counter, df_chunk) in enumerate(csv_reader):\n",
    "    print(f\"Chunk: {counter}\")\n",
    "    # Count all tokens in the chunk (multiply a token by the number of newspaper quoting the quote)\n",
    "    vocabulary = vocabulary +  Counter(chain.from_iterable(df_chunk.explode(\"newspapers\")[\"tokens\"]))\n",
    "\n",
    "# Removing token that appears in only one newspaper\n",
    "processed_voc = list(np.array(list(vocabulary.keys()))[np.array(list(vocabulary.values()))!=1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "192dc5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_voc = sorted(processed_voc)\n",
    "\n",
    "token_to_index = {n:i for i, n in enumerate(sorted_voc)}\n",
    "index_to_token = {i:n for i, n in enumerate(sorted_voc)}\n",
    "\n",
    "with open(PICKLE_TOKEN_TO_INDEX, 'wb') as handle:\n",
    "    pickle.dump(token_to_index,handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open(PICKLE_INDEX_TO_TOKEN, 'wb') as handle:\n",
    "    pickle.dump(index_to_token, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ad69b9",
   "metadata": {},
   "source": [
    "### 3) Create frequency matrix\n",
    "We generate a frequency matrix #newspaper x #tokens: entry (i,j) is the number of time token j appears in newspaper i."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "656044fd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk: 0\n",
      "Chunk: 1\n",
      "Chunk: 2\n",
      "Chunk: 3\n",
      "Chunk: 4\n",
      "Chunk: 5\n",
      "Chunk: 6\n",
      "Chunk: 7\n",
      "Chunk: 8\n",
      "Chunk: 9\n",
      "Chunk: 10\n",
      "Chunk: 11\n",
      "Chunk: 12\n",
      "Chunk: 13\n",
      "Chunk: 14\n",
      "Chunk: 15\n",
      "Chunk: 16\n",
      "Chunk: 17\n",
      "Chunk: 18\n",
      "Chunk: 19\n",
      "Chunk: 20\n",
      "Chunk: 21\n",
      "Chunk: 22\n",
      "Chunk: 23\n",
      "Chunk: 24\n",
      "Chunk: 25\n",
      "Chunk: 26\n",
      "Chunk: 27\n",
      "Chunk: 28\n",
      "Chunk: 29\n",
      "Chunk: 30\n",
      "Chunk: 31\n",
      "Chunk: 32\n",
      "Chunk: 33\n",
      "Chunk: 34\n",
      "Chunk: 35\n",
      "Chunk: 36\n",
      "Chunk: 37\n",
      "Chunk: 38\n",
      "Chunk: 39\n",
      "Chunk: 40\n",
      "Chunk: 41\n",
      "Chunk: 42\n",
      "Chunk: 43\n",
      "Chunk: 44\n",
      "Chunk: 45\n",
      "Chunk: 46\n",
      "Chunk: 47\n",
      "Chunk: 48\n",
      "Chunk: 49\n",
      "Chunk: 50\n",
      "Chunk: 51\n",
      "Chunk: 52\n",
      "Chunk: 53\n",
      "Chunk: 54\n",
      "Chunk: 55\n",
      "Chunk: 56\n",
      "Chunk: 57\n",
      "Chunk: 58\n",
      "Chunk: 59\n",
      "Chunk: 60\n",
      "Chunk: 61\n",
      "Chunk: 62\n",
      "Chunk: 63\n",
      "Chunk: 64\n",
      "Chunk: 65\n",
      "Chunk: 66\n",
      "Chunk: 67\n",
      "Chunk: 68\n",
      "Chunk: 69\n",
      "Chunk: 70\n",
      "Chunk: 71\n",
      "Chunk: 72\n",
      "Chunk: 73\n",
      "Chunk: 74\n",
      "Chunk: 75\n",
      "Chunk: 76\n",
      "Chunk: 77\n",
      "Chunk: 78\n",
      "Chunk: 79\n",
      "Chunk: 80\n",
      "Chunk: 81\n",
      "Chunk: 82\n",
      "Chunk: 83\n",
      "Chunk: 84\n",
      "Chunk: 85\n",
      "Chunk: 86\n",
      "Chunk: 87\n",
      "Chunk: 88\n",
      "Chunk: 89\n",
      "Chunk: 90\n",
      "Chunk: 91\n",
      "Chunk: 92\n",
      "Chunk: 93\n",
      "Chunk: 94\n",
      "Chunk: 95\n",
      "Chunk: 96\n",
      "Chunk: 97\n",
      "Chunk: 98\n",
      "Chunk: 99\n",
      "Chunk: 100\n",
      "Chunk: 101\n",
      "Chunk: 102\n",
      "Chunk: 103\n",
      "Chunk: 104\n",
      "Chunk: 105\n",
      "Chunk: 106\n",
      "Chunk: 107\n",
      "Chunk: 108\n",
      "Chunk: 109\n",
      "Chunk: 110\n",
      "Chunk: 111\n",
      "Chunk: 112\n",
      "Chunk: 113\n",
      "Chunk: 114\n",
      "Chunk: 115\n",
      "Chunk: 116\n",
      "Chunk: 117\n",
      "Chunk: 118\n",
      "Chunk: 119\n",
      "Chunk: 120\n",
      "Chunk: 121\n",
      "Chunk: 122\n",
      "Chunk: 123\n",
      "Chunk: 124\n",
      "Chunk: 125\n",
      "Chunk: 126\n",
      "Chunk: 127\n",
      "Chunk: 128\n",
      "Chunk: 129\n",
      "Chunk: 130\n",
      "Chunk: 131\n",
      "Chunk: 132\n",
      "Chunk: 133\n",
      "Chunk: 134\n",
      "Chunk: 135\n",
      "Chunk: 136\n",
      "Chunk: 137\n",
      "Chunk: 138\n",
      "Chunk: 139\n",
      "Chunk: 140\n",
      "Chunk: 141\n",
      "Chunk: 142\n",
      "Chunk: 143\n",
      "Chunk: 144\n",
      "Chunk: 145\n",
      "Chunk: 146\n",
      "Chunk: 147\n",
      "Chunk: 148\n",
      "Chunk: 149\n",
      "Chunk: 150\n",
      "Chunk: 151\n",
      "Chunk: 152\n",
      "Chunk: 153\n",
      "Chunk: 154\n",
      "Chunk: 155\n",
      "Chunk: 156\n",
      "Chunk: 157\n",
      "Chunk: 158\n",
      "Chunk: 159\n",
      "Chunk: 160\n",
      "Chunk: 161\n",
      "Chunk: 162\n",
      "Chunk: 163\n",
      "Chunk: 164\n",
      "Chunk: 165\n",
      "Chunk: 166\n",
      "Chunk: 167\n",
      "Chunk: 168\n",
      "Chunk: 169\n",
      "Chunk: 170\n",
      "Chunk: 171\n",
      "Chunk: 172\n",
      "Chunk: 173\n",
      "Chunk: 174\n",
      "Chunk: 175\n",
      "Chunk: 176\n",
      "Chunk: 177\n",
      "Chunk: 178\n",
      "Chunk: 179\n",
      "Chunk: 180\n",
      "Chunk: 181\n",
      "Chunk: 182\n",
      "Chunk: 183\n",
      "Chunk: 184\n",
      "Chunk: 185\n",
      "Chunk: 186\n",
      "Chunk: 187\n",
      "Chunk: 188\n",
      "Chunk: 189\n",
      "Chunk: 190\n",
      "Chunk: 191\n",
      "Chunk: 192\n",
      "Chunk: 193\n",
      "Chunk: 194\n",
      "Chunk: 195\n",
      "Chunk: 196\n",
      "Chunk: 197\n",
      "Chunk: 198\n",
      "Chunk: 199\n",
      "Chunk: 200\n",
      "Chunk: 201\n",
      "Chunk: 202\n",
      "Chunk: 203\n",
      "Chunk: 204\n",
      "Chunk: 205\n",
      "Chunk: 206\n",
      "Chunk: 207\n",
      "Chunk: 208\n",
      "Chunk: 209\n",
      "Chunk: 210\n",
      "Chunk: 211\n",
      "Chunk: 212\n",
      "Chunk: 213\n",
      "Chunk: 214\n",
      "Chunk: 215\n",
      "Chunk: 216\n",
      "Chunk: 217\n",
      "Chunk: 218\n",
      "Chunk: 219\n",
      "Chunk: 220\n",
      "Chunk: 221\n",
      "Chunk: 222\n",
      "Chunk: 223\n",
      "Chunk: 224\n",
      "Chunk: 225\n",
      "Chunk: 226\n",
      "Chunk: 227\n",
      "Chunk: 228\n",
      "Chunk: 229\n",
      "Chunk: 230\n",
      "Chunk: 231\n",
      "Chunk: 232\n",
      "Chunk: 233\n",
      "Chunk: 234\n",
      "Chunk: 235\n",
      "Chunk: 236\n",
      "Chunk: 237\n",
      "Chunk: 238\n",
      "Chunk: 239\n",
      "Chunk: 240\n",
      "Chunk: 241\n",
      "Chunk: 242\n",
      "Chunk: 243\n",
      "Chunk: 244\n",
      "Chunk: 245\n",
      "Chunk: 246\n",
      "Chunk: 247\n",
      "Chunk: 248\n",
      "Chunk: 249\n",
      "Chunk: 250\n",
      "Chunk: 251\n",
      "Chunk: 252\n",
      "Chunk: 253\n",
      "Chunk: 254\n",
      "Chunk: 255\n",
      "Chunk: 256\n",
      "Chunk: 257\n",
      "Chunk: 258\n",
      "Chunk: 259\n",
      "Chunk: 260\n",
      "Chunk: 261\n",
      "Chunk: 262\n",
      "Chunk: 263\n",
      "Chunk: 264\n",
      "Chunk: 265\n",
      "Chunk: 266\n",
      "Chunk: 267\n",
      "Chunk: 268\n",
      "Chunk: 269\n",
      "Chunk: 270\n",
      "Chunk: 271\n",
      "Chunk: 272\n",
      "Chunk: 273\n",
      "Chunk: 274\n",
      "Chunk: 275\n",
      "Chunk: 276\n",
      "Chunk: 277\n",
      "Chunk: 278\n",
      "Chunk: 279\n",
      "Chunk: 280\n",
      "Chunk: 281\n",
      "Chunk: 282\n",
      "Chunk: 283\n",
      "Chunk: 284\n",
      "Chunk: 285\n",
      "Chunk: 286\n",
      "Chunk: 287\n",
      "Chunk: 288\n",
      "Chunk: 289\n",
      "Chunk: 290\n",
      "Chunk: 291\n",
      "Chunk: 292\n",
      "Chunk: 293\n",
      "Chunk: 294\n",
      "Chunk: 295\n",
      "Chunk: 296\n",
      "Chunk: 297\n",
      "Chunk: 298\n",
      "Chunk: 299\n",
      "Chunk: 300\n",
      "Chunk: 301\n",
      "Chunk: 302\n",
      "Chunk: 303\n",
      "Chunk: 304\n",
      "Chunk: 305\n",
      "Chunk: 306\n",
      "Chunk: 307\n",
      "Chunk: 308\n",
      "Chunk: 309\n",
      "Chunk: 310\n",
      "Chunk: 311\n",
      "Chunk: 312\n",
      "Chunk: 313\n",
      "Chunk: 314\n",
      "Chunk: 315\n",
      "Chunk: 316\n",
      "Chunk: 317\n",
      "Chunk: 318\n",
      "Chunk: 319\n",
      "Chunk: 320\n",
      "Chunk: 321\n",
      "Chunk: 322\n",
      "Chunk: 323\n",
      "Chunk: 324\n",
      "Chunk: 325\n",
      "Chunk: 326\n",
      "Chunk: 327\n",
      "Chunk: 328\n",
      "Chunk: 329\n",
      "Chunk: 330\n",
      "Chunk: 331\n",
      "Chunk: 332\n",
      "Chunk: 333\n",
      "Chunk: 334\n",
      "Chunk: 335\n",
      "Chunk: 336\n",
      "Chunk: 337\n",
      "Chunk: 338\n",
      "Chunk: 339\n",
      "Chunk: 340\n",
      "Chunk: 341\n",
      "Chunk: 342\n",
      "Chunk: 343\n",
      "Chunk: 344\n",
      "Chunk: 345\n",
      "Chunk: 346\n",
      "Chunk: 347\n",
      "Chunk: 348\n",
      "Chunk: 349\n",
      "Chunk: 350\n",
      "Chunk: 351\n",
      "Chunk: 352\n",
      "Chunk: 353\n",
      "Chunk: 354\n",
      "Chunk: 355\n",
      "Chunk: 356\n",
      "Chunk: 357\n",
      "Chunk: 358\n",
      "Chunk: 359\n",
      "Chunk: 360\n",
      "Chunk: 361\n",
      "Chunk: 362\n",
      "Chunk: 363\n",
      "Chunk: 364\n",
      "Chunk: 365\n",
      "Chunk: 366\n",
      "Chunk: 367\n",
      "Chunk: 368\n",
      "Chunk: 369\n",
      "Chunk: 370\n",
      "Chunk: 371\n",
      "Chunk: 372\n",
      "Chunk: 373\n",
      "Chunk: 374\n",
      "Chunk: 375\n",
      "Chunk: 376\n",
      "Chunk: 377\n",
      "Chunk: 378\n",
      "Chunk: 379\n",
      "Chunk: 380\n",
      "Chunk: 381\n",
      "Chunk: 382\n",
      "Chunk: 383\n",
      "Chunk: 384\n",
      "Chunk: 385\n",
      "Chunk: 386\n",
      "Chunk: 387\n",
      "Chunk: 388\n",
      "Chunk: 389\n",
      "Chunk: 390\n",
      "Chunk: 391\n",
      "Chunk: 392\n",
      "Chunk: 393\n",
      "Chunk: 394\n",
      "Chunk: 395\n",
      "Chunk: 396\n",
      "Chunk: 397\n",
      "Chunk: 398\n",
      "Chunk: 399\n",
      "Chunk: 400\n",
      "Chunk: 401\n",
      "Chunk: 402\n",
      "Chunk: 403\n",
      "Chunk: 404\n",
      "Chunk: 405\n",
      "Chunk: 406\n",
      "Chunk: 407\n",
      "Chunk: 408\n",
      "Chunk: 409\n",
      "Chunk: 410\n",
      "Chunk: 411\n",
      "Chunk: 412\n",
      "Chunk: 413\n",
      "Chunk: 414\n",
      "Chunk: 415\n",
      "Chunk: 416\n",
      "Chunk: 417\n",
      "Chunk: 418\n",
      "Chunk: 419\n",
      "Chunk: 420\n",
      "Chunk: 421\n",
      "Chunk: 422\n",
      "Chunk: 423\n",
      "Chunk: 424\n",
      "Chunk: 425\n",
      "Chunk: 426\n",
      "Chunk: 427\n",
      "Chunk: 428\n",
      "Chunk: 429\n",
      "Chunk: 430\n",
      "Chunk: 431\n",
      "Chunk: 432\n",
      "Chunk: 433\n",
      "Chunk: 434\n",
      "Chunk: 435\n",
      "Chunk: 436\n",
      "Chunk: 437\n",
      "Chunk: 438\n",
      "Chunk: 439\n",
      "Chunk: 440\n",
      "Chunk: 441\n",
      "Chunk: 442\n",
      "Chunk: 443\n",
      "Chunk: 444\n",
      "Chunk: 445\n",
      "Chunk: 446\n",
      "Chunk: 447\n",
      "Chunk: 448\n",
      "Chunk: 449\n",
      "Chunk: 450\n",
      "Chunk: 451\n",
      "Chunk: 452\n",
      "Chunk: 453\n",
      "Chunk: 454\n",
      "Chunk: 455\n",
      "Chunk: 456\n",
      "Chunk: 457\n",
      "Chunk: 458\n",
      "Chunk: 459\n",
      "Chunk: 460\n",
      "Chunk: 461\n",
      "Chunk: 462\n",
      "Chunk: 463\n",
      "Chunk: 464\n",
      "Chunk: 465\n",
      "Chunk: 466\n",
      "Chunk: 467\n",
      "Chunk: 468\n",
      "Chunk: 469\n",
      "Chunk: 470\n",
      "Chunk: 471\n",
      "Chunk: 472\n",
      "Chunk: 473\n",
      "Chunk: 474\n",
      "Chunk: 475\n",
      "Chunk: 476\n",
      "Chunk: 477\n",
      "Chunk: 478\n",
      "Chunk: 479\n",
      "Chunk: 480\n",
      "Chunk: 481\n",
      "Chunk: 482\n",
      "Chunk: 483\n",
      "Chunk: 484\n",
      "Chunk: 485\n",
      "Chunk: 486\n",
      "Chunk: 487\n",
      "Chunk: 488\n",
      "Chunk: 489\n",
      "Chunk: 490\n",
      "Chunk: 491\n",
      "Chunk: 492\n",
      "Chunk: 493\n",
      "Chunk: 494\n",
      "Chunk: 495\n",
      "Chunk: 496\n",
      "Chunk: 497\n",
      "Chunk: 498\n",
      "Chunk: 499\n",
      "Chunk: 500\n",
      "Chunk: 501\n",
      "Chunk: 502\n",
      "Chunk: 503\n",
      "Chunk: 504\n",
      "Chunk: 505\n",
      "Chunk: 506\n",
      "Chunk: 507\n",
      "Chunk: 508\n",
      "Chunk: 509\n",
      "Chunk: 510\n",
      "Chunk: 511\n",
      "Chunk: 512\n",
      "Chunk: 513\n",
      "Chunk: 514\n",
      "Chunk: 515\n",
      "Chunk: 516\n",
      "Chunk: 517\n",
      "Chunk: 518\n",
      "Chunk: 519\n",
      "Chunk: 520\n",
      "Chunk: 521\n",
      "Chunk: 522\n",
      "Chunk: 523\n",
      "Chunk: 524\n"
     ]
    }
   ],
   "source": [
    "csv_reader = pd.read_csv(FILE_NEWSPAPER_TOKEN, chunksize=10_000,compression='bz2', converters={\"newspapers\": ast.literal_eval,\"tokens\":ast.literal_eval}) \n",
    "\n",
    "def dummy(doc):\n",
    "    return doc\n",
    "vectorizer = CountVectorizer(tokenizer=dummy,preprocessor=dummy, vocabulary=sorted_voc) \n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame({'newspapers':newspapers})\n",
    "\n",
    "for (counter, df_chunk) in enumerate(csv_reader):\n",
    "    print(f\"Chunk: {counter}\")\n",
    "    \n",
    "    df_exploded = df_chunk.explode(\"newspapers\")\n",
    "    \n",
    "    # Create dataframe with all the tokens per newspaper\n",
    "    df_grouped = df_exploded.groupby(\"newspapers\")[\"tokens\"].apply(sum).reset_index() \n",
    "    \n",
    "    # Join previous dataframe with a dumb dataframe containing all the newspaper as index\n",
    "    # => Add empty newspaper, allow to create frequency matrix with the correct index for newspaper\n",
    "    df_join = df.set_index('newspapers').join(df_grouped.set_index('newspapers'))\n",
    "    df_join[\"tokens\"] = np.where(df_join[\"tokens\"].isna(), [\"\"], df_join[\"tokens\"])\n",
    "    \n",
    "    # Create token frequency vector by newspaper\n",
    "    X = vectorizer.fit_transform(df_join[\"tokens\"])\n",
    "    \n",
    "    # Sum all the token x newspaper frequency matrix\n",
    "    if(counter == 0):\n",
    "        newspaper_token_frequency = X\n",
    "    else:\n",
    "        newspaper_token_frequency += X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e148cdb9",
   "metadata": {},
   "source": [
    "### 4) Create TF-IDF matrix and write it to a file\n",
    "Transform the frequency matrix into a TF-IDF matrix. Each row is normalised and each column is scaled by proportionnaly to the number of newspaper in which the speaker is quoted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "afddd7dd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "transformer = TfidfTransformer()\n",
    "newspaper_token_tfidf = transformer.fit_transform(newspaper_token_frequency)\n",
    "sparse.save_npz(FILE_NEWSPAPER_TOKEN_TFIDF, newspaper_token_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a9c57b",
   "metadata": {},
   "source": [
    "## Stats about the processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a0eefe55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "They are 2434410 pairs of (newspapers,speakers)\n",
      "They are 7362 unique newspapers\n",
      "They are 212146 unique speakers\n"
     ]
    }
   ],
   "source": [
    "df = newspaper_speaker_count\n",
    "\n",
    "print(f'They are {len(df)} pairs of (newspapers,speakers)')\n",
    "newspapers = set(df['newspaper'])\n",
    "print(f'They are {len(newspapers)} unique newspapers')\n",
    "speakers = set(df['speaker'])\n",
    "print(f'They are {len(speakers)} unique speakers')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc7ee05a",
   "metadata": {},
   "source": [
    "#### Number of time a speaker has been quoted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "566473de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speaker</th>\n",
       "      <th>total_quotes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>149814</th>\n",
       "      <td>none</td>\n",
       "      <td>5857313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161395</th>\n",
       "      <td>president donald trump</td>\n",
       "      <td>261722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24574</th>\n",
       "      <td>boris johnson</td>\n",
       "      <td>86315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94541</th>\n",
       "      <td>joe biden</td>\n",
       "      <td>84953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20952</th>\n",
       "      <td>bernie sanders</td>\n",
       "      <td>69722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194583</th>\n",
       "      <td>tedros adhanom ghebreyesus</td>\n",
       "      <td>67672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180703</th>\n",
       "      <td>scott morrison</td>\n",
       "      <td>60324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10674</th>\n",
       "      <td>andrew cuomo</td>\n",
       "      <td>54054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161405</th>\n",
       "      <td>president trump</td>\n",
       "      <td>53481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14547</th>\n",
       "      <td>anthony fauci</td>\n",
       "      <td>49239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145222</th>\n",
       "      <td>nancy pelosi</td>\n",
       "      <td>47032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58674</th>\n",
       "      <td>elizabeth warren</td>\n",
       "      <td>42928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132876</th>\n",
       "      <td>matt hancock</td>\n",
       "      <td>41480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141246</th>\n",
       "      <td>mike pompeo</td>\n",
       "      <td>41392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1902</th>\n",
       "      <td>adam schiff</td>\n",
       "      <td>34763</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           speaker  total_quotes\n",
       "149814                        none       5857313\n",
       "161395      president donald trump        261722\n",
       "24574                boris johnson         86315\n",
       "94541                    joe biden         84953\n",
       "20952               bernie sanders         69722\n",
       "194583  tedros adhanom ghebreyesus         67672\n",
       "180703              scott morrison         60324\n",
       "10674                 andrew cuomo         54054\n",
       "161405             president trump         53481\n",
       "14547                anthony fauci         49239\n",
       "145222                nancy pelosi         47032\n",
       "58674             elizabeth warren         42928\n",
       "132876                matt hancock         41480\n",
       "141246                 mike pompeo         41392\n",
       "1902                   adam schiff         34763"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speaker_total_occurence = df.groupby('speaker',as_index=False).aggregate({'count':'sum'})\\\n",
    "                                .rename(columns = {'count':'total_quotes'})\n",
    "speaker_total_occurence.nlargest(15, columns=['total_quotes'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff74685",
   "metadata": {},
   "source": [
    "#### Number of unique speaker by newspaper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9c87226a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>newspaper</th>\n",
       "      <th>speaker_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4055</th>\n",
       "      <td>msn</td>\n",
       "      <td>16544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>784</th>\n",
       "      <td>breitbart</td>\n",
       "      <td>9434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6872</th>\n",
       "      <td>washingtontimes</td>\n",
       "      <td>9239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5439</th>\n",
       "      <td>sfgate</td>\n",
       "      <td>8864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2954</th>\n",
       "      <td>indiatimes</td>\n",
       "      <td>7304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4518</th>\n",
       "      <td>nytimes</td>\n",
       "      <td>7277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5405</th>\n",
       "      <td>seattletimes</td>\n",
       "      <td>6951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2938</th>\n",
       "      <td>independent</td>\n",
       "      <td>6501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5686</th>\n",
       "      <td>stamfordadvocate</td>\n",
       "      <td>6426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>businessinsider</td>\n",
       "      <td>6422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1478</th>\n",
       "      <td>ctpost</td>\n",
       "      <td>6411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6140</th>\n",
       "      <td>thehour</td>\n",
       "      <td>6277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4340</th>\n",
       "      <td>newstimes</td>\n",
       "      <td>6222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4378</th>\n",
       "      <td>nhregister</td>\n",
       "      <td>6066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5769</th>\n",
       "      <td>stuff</td>\n",
       "      <td>6007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             newspaper  speaker_count\n",
       "4055               msn          16544\n",
       "784          breitbart           9434\n",
       "6872   washingtontimes           9239\n",
       "5439            sfgate           8864\n",
       "2954        indiatimes           7304\n",
       "4518           nytimes           7277\n",
       "5405      seattletimes           6951\n",
       "2938       independent           6501\n",
       "5686  stamfordadvocate           6426\n",
       "890    businessinsider           6422\n",
       "1478            ctpost           6411\n",
       "6140           thehour           6277\n",
       "4340         newstimes           6222\n",
       "4378        nhregister           6066\n",
       "5769             stuff           6007"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newspaper_speaker_count = df.groupby('newspaper',as_index=False).aggregate({'speaker':'count'})\\\n",
    "                            .rename(columns = {'speaker':'speaker_count'})\n",
    "newspaper_speaker_count.nlargest(15, columns=['speaker_count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa744e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
