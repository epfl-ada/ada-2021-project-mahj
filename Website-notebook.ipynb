{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa0ac9e6",
   "metadata": {},
   "source": [
    "# Le plan: \n",
    "\n",
    "When one wants to get information \n",
    "## 1. Blabla intro du sujet TODO\n",
    "\n",
    "## 2. What is our goal?\n",
    "\n",
    "## 3. How do we achieve it (in short)?\n",
    "~Use Quotebank + Unsupervised learning\n",
    "\n",
    "## 4. Data story\n",
    "\n",
    "## 5. Conclusions: \n",
    "### 5.1 What did we find?\n",
    "### 5.2 What's next/would be interesting to do\n",
    "\n",
    "### somewhere:\n",
    "Indicate that we alternatively the terms speaker/citee/quotee, journal/media/newspaper, and group/consortium"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d7653a3",
   "metadata": {},
   "source": [
    "# 1. Intro du sujet: TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28fdb3c1",
   "metadata": {},
   "source": [
    "# 2. Our goal:\n",
    "We aim to show that we can recognize which media group a journal belongs to, using some automatic clustering algorithm using very little data. As a result, we will have shown a lack of diversity of these journals, thus showing that if you want to be well-informed, simply reading different newspapers is not enough. One needs to pay attention to more than that."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b58320",
   "metadata": {},
   "source": [
    "# 3. How we achieve that:\n",
    "\n",
    "\\[For a detailed description of the process, keep reading, or better, go see our [notebook](https://github.com/epfl-ada/ada-2021-project-mahj)\\].\n",
    "\n",
    "\n",
    "We need some *features* which allow us to distinguish between diferent media. To do so we use the [Quotebank](https://dlab.epfl.ch/people/west/pub/Vaucher-Spitz-Catasta-West_WSDM-21.pdf) database, which is a dataset of  speaker-attributed quotations that were extracted from diverse English news articles[^1].\n",
    "\n",
    "[^1]: https://zenodo.org/record/4277311\n",
    "\n",
    "We then augment this dataset using [Wikidata](https://www.wikidata.org/wiki/Wikidata:Main_Page) to get the features we deemed necessary for our analysis.\n",
    "\n",
    "**TODO: commenter la taille  É N O R M E  du dataset qu'on a?**  \n",
    "**TODO: refine last paragraph**\n",
    "After getting all those features, we use [Natural language processing](https://en.wikipedia.org/wiki/Natural_language_processing)-techniques (or NLP) to cluster media, and see what we find.\n",
    "**TODO: expliquer pk on ne prend qu'une année. E.g. pcque les news changent bcp entre les années, esp with covid / different presidents, ...**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d51d08",
   "metadata": {},
   "source": [
    "# 4. But more precisely, what did you do?:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "617d54e8",
   "metadata": {},
   "source": [
    "### 4.1: data-extension\n",
    "Well for starters, the data we extract from the Quotebank-dataset look like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4dfea30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ici quelques extraits de la data de quotebank avec juste les attributs qu'on a gardés\n",
    "\n",
    "# Ou ptetre ?:\n",
    " # 1: original\n",
    " # 2: ce qu'on a gardé"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118ab205",
   "metadata": {},
   "source": [
    "As you can see, the owners of the media are not indicated here, so we need to extend our dataset with these features.  \n",
    "If we can't automatically find a journal's parent group, we decide to throw it away.\n",
    "We also do so if the journals are lonely children. Indeed, we seek (**todo: above all/firstly**) to cluster them according to their parent groups, so isolated media are irrelevant.\n",
    "\n",
    "**TODO? \"see file Wikidata_scraping.ipynb\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "703511c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Excerpt of wikidata code for scraping?\n",
    "# Exemple de à quoi ressemble les infos obtenues / la nouvelle data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "820d8022",
   "metadata": {},
   "source": [
    "### 4.2: Data processing?\n",
    "Since for each we have both quotes, and quotees (i.e. the people quoted), it seems natural to try and cluster them according to these 2 features. Let us then try 2 different methods:\n",
    " * First, cluster according to which speakers are cited in it.\n",
    " * Second, cluster according to the text content of the extracted quotes.\n",
    " \n",
    "**TODO: see file \"Process_data.ipynb\" for more details**\n",
    "**TODO: do we speak about the distance metrics?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5080bc33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For 1, do a small graph like:\n",
    "# journal i:\n",
    "  # speaker 1\n",
    "  # speaker 2\n",
    "  # ...\n",
    "  # speaker n\n",
    "\n",
    "# For 2, do sth like:\n",
    "# journal j:\n",
    "  # quote 1\n",
    "  # quote 2\n",
    "  # ...\n",
    "  # quote m\n",
    "\n",
    "# Maybe 1 on the left, and 1 on the right."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1289bd86",
   "metadata": {},
   "source": [
    "For both these features, we will first use the [Term Frequency-Inverse Document Frequency](https://en.wikipedia.org/wiki/Tf%E2%80%93idf) method (TF-IDF for short) (**todo: better name?**) before proceeding to further analysis.  \n",
    "In a nutshell, this method allows one to measure the importance of a term[^1] to a document[^2] in a collection[^3] based on its number of apparitions.\n",
    "\n",
    "[^1]: Here a citee, or a word\n",
    "[^2]: Here a media\n",
    "[^3]: Here, all the media we have kept"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ec1cf0",
   "metadata": {},
   "source": [
    "**TODO: maybe a bit long?**\n",
    "Basically this method gives to each word a weight:\n",
    " * *proportional* to its number of occurences in d (term frequency)\n",
    " * and *inversely proportional* to its presence in the corpus (inverse document frequency)[^1]\n",
    "\n",
    "The reasoning is that we use the **IDF** to **find** words **unique** to each document, or **remove recurrent** words, which we find in basically every document, and therefore don't bring any information (e.g. stopwords such as 'the' in a text).  \n",
    "We use the **TF** to find words that **appear often**, as they may be **characteristic** of a particular document. For example the word 'brain' may often appear in a neuroscience paper, while not so much in a geography one.\n",
    "\n",
    "[^1]: to quantify the 'presence' of a word in the corpus, we simply count the number of documents in which it occurs. We don't take its occurences per document into account here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0ab791e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Illustrations: les formes des 2 matrices obtenues, peu importe les coefs\n",
    "\n",
    "# Though on peut mettre une petit flèche vers\n",
    "# la matrice journal-speaker[i, j] par ex."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56e0e0c",
   "metadata": {},
   "source": [
    "### 4.3: Data analysis (the heart of our problem)\n",
    "**TODO: see file \"Analysis.ipynb\" for more details**\n",
    "\n",
    "Now that we have processed our data, we need to visualize it.  \n",
    "The problem is that the data (our TF-IDF matrices) is inherently high-dimensional, so we as humans can't directly visualize it. That is why we transform our matrices using [Singular Value Decomposition](https://en.wikipedia.org/wiki/Singular_value_decomposition) (SVD).\n",
    "\n",
    "This transformation should allow us to extract \"[topics](https://en.wikipedia.org/wiki/Topic_model)\", which correspond to the (orthonormal) directions of highest variation and their importance. We can then view the differences between different media along one such topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fe1fbe38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some illustration of SVD, or maybe of PCA to get the idea?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02804d5d",
   "metadata": {},
   "source": [
    "Let us apply this technique on the speakers matrix first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2e13e6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Illustration des projections qu'on a au départ, avec la séparation géographique."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c46aa2",
   "metadata": {},
   "source": [
    "Using the top speakers per axe, we identify the *topics* of the axes:\n",
    "\n",
    "| Axis | Max                 | Min                     |\n",
    "|------|---------------------|-------------------------|\n",
    "| 0    | Frequent speakers   | Non Frequent speakers   |\n",
    "| 1    | US speakers         | UK speakers             |\n",
    "| 2    | Australian speakers | US speakers             |\n",
    "| 3    | Canadian speakers   | US politician speakers  |\n",
    "| 4    | Basketball speakers | US politicians speakers |\n",
    "\n",
    "As you can see, the speakers are very different in newspapers from different countries which results in clustering mostly based on the country of origin of the newspapers.  \n",
    "It makes sense: UK-media will cite more UK-speakers, while USA-media will cite more USA-speakers. \n",
    "\n",
    "So our clustering works (for example it is easy to recognize journals from the media group *News Corp Australia*), but it is not enough yet. \n",
    "Indeed, even if one is aware they should get their information from different media, are they really that likely to get it from different countries' media? Of course not, and that might be especially true for American people (**TODO: is there some study that says american are self centered? or at least we can find some about the nb of languages they know.**). \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb456a12",
   "metadata": {},
   "source": [
    "Then let us see if we can differentiate the media *inside one country!*. We will focus on the USA since it is the country with the most data available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c1c7b866",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the list of plots \"speaker with only USA\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7191b87",
   "metadata": {},
   "source": [
    "Again we can try and extract the *topics* from the list of top speakers per axe:\n",
    "\n",
    "| Axis | Max                             | Min                                              |\n",
    "|------|---------------------------------|--------------------------------------------------|\n",
    "| 0    | Frequent speakers               | Non Frequent speakers                          |\n",
    "| 1    | Sport coaches of Los Angeles    | West coast personalities                       |\n",
    "| 2    | Sport coaches of San Francisco  | Sport coaches/DJ of Los Angeles                |\n",
    "\n",
    "We also see (in bright green) that journals from *Townsquare Media* explain most of the variance of several axes, namely the 3rd and the 4th.  \n",
    "Hence although we can visually recognize media from this group, it might be interesting to redo our analysis while removing media from this group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad44ed3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3253591d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee5fba3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4465ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9916f6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2cecc4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6a1535",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7c3d03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d2a94f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2677be7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2528093b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4057c33f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c939e6b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d19be60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809f4f46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2460d07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f09f9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ed51b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15fd50ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e6c38c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db9e5f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2232fd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9155a62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6714a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910b2d3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6eca78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00398eb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625ab823",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee48f12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0572f4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318c1fdc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88038153",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1b57ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ada] *",
   "language": "python",
   "name": "conda-env-ada-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
